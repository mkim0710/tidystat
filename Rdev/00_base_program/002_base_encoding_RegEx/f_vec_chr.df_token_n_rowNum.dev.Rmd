---
##HHHHHHHHHHHHHHHHHH BEGINNING OF TABLE OF CONTENTS HHHHHHHHHHHHHHHHHHHHHH##  
# TABLE OF CONTENTS (level 1) ----  
# @@ REFERENCES)                                                            #L247
# @@ DATA) example                                                          #L256
# @@ START) dev                                                             #L276
# @@ SOURCE)                                                                #L311
# @@ START) function                                                        #L353
# @@ MetaData) Read & Check                                                 #L402
# @@ DATA) Read & Check                                                     #L472
# @@ ANALYSIS) (Breif) byVar =                                              #L638
# @@ DATA) mutate()                                                         #L644
# @@ DATA) filter() -> New DS                                               #L675
# @@ DATA) select(matches(VarName.suffix.regex))                            #L708
# @@ ANALYSIS) byVar =                                                      #L722
##HHHHHHHHHHHHHHHHHHHH THE END OF TABLE OF CONTENTS HHHHHHHHHHHHHHHHHHHHHH##   
##HHHHHHHHHHHHHHHHHH BEGINNING OF TABLE OF CONTENTS HHHHHHHHHHHHHHHHHHHHHH##  
# TABLE OF CONTENTS (level 1) ----  
# @@ REFERENCES)                                                            # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L247
# @@ DATA) example                                                          # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L256
# @@ START) dev                                                             # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L276
# @@ SOURCE)                                                                # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L311
# @@ START) function                                                        # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L353
# @@ MetaData) Read & Check                                                 # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L402
# @@ DATA) Read & Check                                                     # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L472
# @@ ANALYSIS) (Breif) byVar =                                              # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L638
# @@ DATA) mutate()                                                         # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L644
# @@ DATA) filter() -> New DS                                               # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L675
# @@ DATA) select(matches(VarName.suffix.regex))                            # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L708
# @@ ANALYSIS) byVar =                                                      # https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd#L722
##HHHHHHHHHHHHHHHHHHHH THE END OF TABLE OF CONTENTS HHHHHHHHHHHHHHHHHHHHHH##   
# cmd /C C:/PROGRA~2/MICROS~1/Edge/APPLIC~1/msedge_proxy.exe --app=https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd
# https://forum.posit.co/t/when-to-use-yaml-vs-when-to-use-setup-code-chunk/56169/  
title: "`r params$doc_title`"
author: "MHKim"
date: "`r Sys.setlocale('LC_ALL', 'en_US.utf8'); format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:  
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_sections: false
    code_folding: none
    df_print: tibble
    highlight: textmate
    fig_width: 10
    fig_height: 6
  html_document:
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_sections: false
    df_print: tibble
    code_folding: none
    highlight: textmate
    fig_width: 10
    fig_height: 6
  pdf_document: 
    toc: yes
    toc_depth: 6
    fig_width: 10
    fig_height: 6
    latex_engine: xelatex  # mainfont, sansfont, monofont, mathfont works only with xelatex and lualatex, but not pdflatex
    keep_tex: true
  word_document:
    toc: yes
    toc_depth: 6
    fig_width: 9
    fig_height: 6
# documentclass: scrartcl  # https://pandoc.org/MANUAL.html#variables-for-latex
# classoption: fontsize=9pt 
geometry: portrait, a3paper, margin=20mm # https://bookdown.org/yihui/rmarkdown/pdf-document.html#latex-options
# fontsize: 12pt
header-includes: 
  - \usepackage{fontspec}
  - \newcommand{\setfallbackfont}[4]{
      \IfFontExistsTF{#2}
        {#1{#2}}
        {\IfFontExistsTF{#3}
          {#1{#3}}
          {#1{#4}}}}
  # - \setfallbackfont{\setmainfont}{Roboto Condensed}{Noto Sans Condensed}{Arial Narrow}
  # - \setfallbackfont{\setsansfont}{Roboto Condensed}{Noto Sans Condensed}{Arial Narrow}
  - \setfallbackfont{\setmainfont}{Roboto}{Noto Sans}{Arial}
  - \setfallbackfont{\setsansfont}{Roboto}{Noto Sans}{Arial}
  - \setfallbackfont{\setmonofont}{Cascadia Code SemiBold}{Cascadia Code}{Fira Code}
  - \usepackage[hangul]{kotex}
  # - \setfallbackfont{\setmainhangulfont}{NanumGothic}{HCR Dotum LVT}{Malgun Gothic}
  # - \setfallbackfont{\setsanshangulfont}{NanumGothic}{HCR Dotum LVT}{Malgun Gothic}
  # - \setfallbackfont{\setmonohangulfont}{D2Coding}{NanumGothicCoding}{NanumGothic}
params:
  doc_title: !r basename(rstudioapi::getSourceEditorContext()$path)
# https://stackoverflow.com/questions/55751815/r-markdown-difference-between-parameters-and-variables
# ?rmarkdown::html_document
---
<!-- https://stackoverflow.com/questions/28480625/r-knitr-markown-setting-html-page-width -->
<style type="text/css">
.main-content, .toc {max-width: 785px; margin: 0 auto; font-size: 1rem;} /* A4: 21cm x 29.7cm = 8.27in x 11.69in; 8.27in x 96px/in ≈ 793px */
html { font-size: 12px; }
body { font-size: 12px; font-family: 'Roboto Condensed', 'Noto Sans Condensed', 'Open Sans Condensed', 'Source Sans 3', 'Arial Narrow', Helvetica, sans-serif; }
h1.title { font-size: 28px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 14px; margin-bottom: 0; color: Navy; }
h1 { font-size: 24px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 12px; margin-bottom: 0; color: Navy; }
h2 { font-size: 21px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 11px; margin-bottom: 0; color: Navy; }
h3 { font-size: 18px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 9px; margin-bottom: 0; color: Navy; }
h4 { font-size: 16px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 8px; margin-bottom: 0; color: Navy; }
h5 { font-size: 14px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 7px; margin-bottom: 0; color: Navy; }
h6 { font-size: 12px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 6px; margin-bottom: 0; color: Navy; }
table, td, th, figure, figcaption { font-size: 10px; font-family: 'Roboto Condensed', 'Noto Sans Condensed', 'Open Sans Condensed', 'Source Sans 3', 'Arial Narrow', Helvetica, sans-serif; line-height: 1.1; margin-top: 5px; margin-bottom: 0; }
code { font-size: 11px; font-family: 'Cascadia Code SemiBold', 'Cascadia Code', 'Fira Code', Consolas, 'Source Code Pro', monospace; line-height: 1.1; margin-top: 6px; margin-bottom: 0; color: DimGray; background-color: Snow; }
pre { font-size: 11px; font-family: 'Cascadia Code SemiBold', 'Cascadia Code', 'Fira Code', Consolas, 'Source Code Pro', monospace; line-height: 1.1; margin-top: 6px; margin-bottom: 0; color: DimGray; background-color: Snow; }
</style>
  
<!-- font-size: 0.9em; /* 90% of inherited font size */ -->
  
<!-- Body text (body): The default font size is typically 16 pixels. -->
<!-- Paragraphs (p): Inherit the body's font size, so also typically 16 pixels. -->
<!-- List items (li): Inherit the body's font size, generally 16 pixels. -->
<!-- Headings (h1 to h6): The default sizes decrease with each level. For example: -->
<!-- h1: Typically around 32 pixels. -->
<!-- h2: Often around 24 pixels. -->
<!-- h3: Commonly around 18.72 pixels. -->
<!-- h4: Usually about 16 pixels. -->
<!-- h5: Generally around 13.28 pixels. -->
<!-- h6: Often about 10.72 pixels. -->
<!-- Blockquotes (blockquote): Usually inherit the body's font size, around 16 pixels. -->
<!-- Tables (table), table cells (td, th): Typically inherit the body's font size, so around 16 pixels. -->
<!-- Figures (figure) and figure captions (figcaption): Generally inherit the body's font size, so about 16 pixels. -->
<!-- 1: Approximately 8 pixels. -->
<!-- 2: Approximately 10 pixels. -->
<!-- 3: Approximately 12 pixels (this was often considered the default size). -->
<!-- 4: Approximately 14 pixels. -->
<!-- 5: Approximately 18 pixels. -->
<!-- 6: Approximately 24 pixels. -->
# __________|------  
<!-- {r Rstudio-RMarkDown-Shortcuts, eval=FALSE, include=FALSE} -->
<!-- ##### Rstudio RMarkDown Shortcuts -->
<!-- https://support.posit.co/hc/en-us/articles/200711853-Keyboard-Shortcuts-in-the-RStudio-IDE   -->
<!-- https://bookdown.org/yihui/rmarkdown-cookbook/rstudio-shortcuts.html   -->
<!-- Insert R chunk	Ctrl+Alt+I	Command+Option+I   -->
<!-- Preview HTML	Ctrl+Shift+K	Command+Shift+K   -->
<!-- Run all chunks above	Ctrl+Alt+P	Command+Option+P   -->
<!-- Run current chunk	Ctrl+Alt+C	Command+Option+C   -->
<!-- Run current chunk	Ctrl+Shift+Enter	Command+Shift+Enter   -->
<!-- Run next chunk	Ctrl+Alt+N	Command+Option+N   -->
<!-- Run all chunks	Ctrl+Alt+R	Command+Option+R   -->
<!-- Go to next chunk/title	Ctrl+PgDown	Command+PgDown   -->
<!-- Go to previous chunk/title	Ctrl+PgUp	Command+PgUp   -->
<!-- Show/hide document outline	Ctrl+Shift+O	Command+Shift+O   -->
<!-- F7 spell-check your document.   -->
<!-- Restart the R session   Ctrl + Alt + F10 (or Command + Option + F10 on macOS).   -->
<!--    -->
<!-- *** Caution: @ # \$ \% * \\ ***  -->

  
```{r setup, echo=FALSE, results="hide"}
## Cf) {r setup, eval=TRUE, include=FALSE}
if(Sys.info()["sysname"] == "Windows") Sys.setlocale("LC_ALL", "en_US.UTF-8")  # Note that setting category "LC_ALL" sets only categories "LC_COLLATE", "LC_CTYPE", "LC_MONETARY" and "LC_TIME".
# Sys.setlocale("LC_MESSAGES", "en_US.utf8")  # Note that the LANGUAGE environment variable has precedence over "LC_MESSAGES" in selecting the language for message translation on most R platforms.  # LC_MESSAGES does not exist in Windows
Sys.setenv(LANGUAGE="en_US");  # Sys.getenv("LANGUAGE");    # Note that the LANGUAGE environment variable has precedence over "LC_MESSAGES" in selecting the language for message translation on most R platforms.
# str(knitr::opts_chunk$get())
# cat(deparse(knitr::opts_chunk$get(), width.cutoff=120), "  \n", sep="")
# list(eval=TRUE, echo=TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = "##",     highlight = TRUE, size = "normalsize", background = "#F7F7F7", strip.white = structure(TRUE, class = "AsIs"), cache = FALSE,     cache.path = "cache/", cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, autodep = FALSE, cache.rebuild = FALSE,     fig.keep = "high", fig.show = "asis", fig.align = "default", fig.path = "figure/", dev = NULL, dev.args = NULL, dpi = 72,     fig.ext = NULL, fig.width=7, fig.height=7, fig.env = "figure", fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:",     fig.subcap = NULL, fig.pos = "", out.width=NULL, out.height=NULL, out.extra = NULL, fig.retina = 1, external = TRUE,     sanitize = FALSE, interval = 1, aniopts = "controls,loop", warning = TRUE, error = TRUE, message = TRUE, render = NULL,     ref.label = NULL, child = NULL, engine = "R", split = FALSE, include = TRUE, purl = TRUE)
knitr::opts_chunk$set(
    eval=TRUE, echo=FALSE, results="markup", collapse=TRUE, # In Rstudio Notebook Source Pane & nb.HTML, results="hold" does not work
    comment="#", fig.width=10, fig.height=6, # In Rstudio Notebook Source Pane & nb.HTML, comment="##" does not work?
    warning=TRUE, message=TRUE, include=TRUE, 
    error=FALSE,  # error=TRUE: show the errors without stopping R; error=FALSE: stop on error
    tidy.opts=list(width.cutoff=120), tidy=FALSE, 
    R.options = list(width=120), paged.print=FALSE
) 
# knitr::opts_chunk$set(message=TRUE) & {r, results="hide"} -> message shown in Rstudio Notebook Source Pane & knitted HTML, but not in Preview nb.HTML?!
# knitr::opts_chunk$set(message=FALSE) & {r, message=TRUE, results="hide"} -> message shown in Rstudio Notebook Source Pane & knitted HTML, but not in Preview nb.HTML?!
# *** results="hide": results shown only on Rstudio Notebook Source Pane, but not in nb.HTML nor knitted HTML
knitr::opts_knit$set(global.par = TRUE)


## Cf) {r loadPackages-NoEchoHideResults, echo=FALSE, results="hide"}
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# cmd /C C:/PROGRA~2/MICROS~1/Edge/APPLIC~1/msedge_proxy.exe --app=https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/default.R
# cmd /C C:/PROGRA~2/MICROS~1/Edge/APPLIC~1/msedge_proxy.exe --app=https://github.com/mkim0710/tidystat/blob/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# cmd /C C:/PROGRA~2/MICROS~1/Edge/APPLIC~1/msedge_proxy.exe --app=https://github.com/mkim0710/tidystat/blob/master/.Rprofile    
#| ------------------------- < To be covered at .Rprofile > --------------------- |#  
if(!exists("env1", envir=.GlobalEnv)) {  message('> source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")')  ;  source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")  ;  .First()  }  
if(!".Rprofile" %in% names(.GlobalEnv$env1$source)) {  message('> source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")')  ;  source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")  ;  .First()  }  
##________________________________________________________________________________  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
env1$info$options.width = getOption("width"); cat('\tgetOption("width") == ', env1$info$options.width, "  \n", sep="")
#   
## Cf) {r env1-Info-NoEchoHideResults, echo=FALSE, results="hide"}
# https://yihui.org/knitr/options/#package-options
env1$info$info_software_versions = env1$env.internal.attach$get_software_versions(library_names = c("tidyverse", "dplyr", "ggplot2", "purrr", "stringr", "stats","survival"))
# str(env1$info$info_software_versions)


###### env1\$info\$DocumentTitle1 ----  
# ```{r env1-DocumentTitle1-NoEchoHideResults, echo=FALSE, results="hide"}
env1$info$DocumentTitle0 = paste0("00env1.minimum","-",basename(getwd()))
env1$info$DocumentTitle1 = paste0(env1$info$DocumentTitle0,"@", ifelse(grepl("MacBook-Pro", Sys.info()["nodename"]), "MBP", Sys.info()["nodename"]))
cat(env1$info$DocumentTitle0,"-",format(Sys.time(),"%y%m%d"), "\n", 
    env1$info$DocumentTitle0,"-",format(Sys.time(),"%y%m%d"),".Rmd", "\n", 
    env1$info$DocumentTitle0,"-dev",format(Sys.time(),"%y%m%d"),".Rmd", "\n", 
    env1$info$DocumentTitle0,"-clean",format(Sys.time(),"%y%m%d"),".Rmd", "\n", 
    sep="")
```
  
  
```{r env1-Path-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
###### env1\$path ----  
# cat(" getwd() == "); dput(getwd())  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
### env1\$path\$LastSourceEditorContext.path_filename_ext ====  
# *** Caution) In Rstudio Notebook, the path of the running Rmd file is set as the working directory~!!!
# env1$path$LastSourceEditorContext.path_filename_ext = rstudioapi::getSourceEditorContext()$path |> normalizePath(winslash="/",mustWork=NA) |> str_replace(fixed(getwd()|>normalizePath(winslash="/",mustWork=NA)), "") |> str_replace("^/", "")
# env1$path$LastSourceEditorContext.path_filename_ext = rstudioapi::getSourceEditorContext()$path |> normalizePath(winslash="/",mustWork=NA) |> str_replace(fixed(env1$path$path1|>normalizePath(winslash="/",mustWork=NA)), "") |> str_replace("^/", "")
env1$path$LastSourceEditorContext.path_filename_ext = rstudioapi::getSourceEditorContext()$path |> normalizePath(winslash="/",mustWork=NA)    # Caution) Not using a relative path~!
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# env1$path$project_base = "Rproject_HEALS0215"
# env1$path$data_suffix = "_01"
# # env1$path$data_suffix = ""
# env1$path$project_suffix = "GJ3"
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
# env1$path$.path4read = file.path(env1$path$path0, paste0(env1$path$project_base, env1$path$data_suffix))
# env1$path$.path4write = file.path(env1$path$.path4read, paste0(env1$path$project_base, env1$path$data_suffix, env1$path$project_suffix))
env1$path$.path4read = ifelse(is.na(env1$path$path1), getwd(), env1$path$path1)
env1$path$.path4write = getwd()
.path4read  = env1$path$.path4read
.path4write = env1$path$.path4write
# cat(" > str(env1$path)\n"); str(env1$path, max.level = 1, give.attr = F)  

## @ env1 |> as.list() |> str(max.level = 2, give.attr = FALSE) ----  
"ls(all.names = TRUE, envir = .GlobalEnv) |> set_names() |> map(get) |> str(max.level = 1, give.attr = FALSE)" |> env1$f$f_CodeText.ECHO(EXECUTE = TRUE, deparse_cat = FALSE, LinePrefix4CodeText = "> ", LinePrefix4Output = "")
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
".tmp |> str(max.level = 1, give.attr = FALSE)" |> env1$f$f_CodeText.ECHO(EXECUTE = TRUE, deparse_cat = FALSE, LinePrefix4CodeText = "> ", LinePrefix4Output = "")
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
"env1 |> as.list() |> env1$f$f_list.str_by_element(max.level = 2, give.attr = FALSE)" |> env1$f$f_CodeText.ECHO(EXECUTE = TRUE, deparse_cat = FALSE, LinePrefix4CodeText = "> ", LinePrefix4Output = "")
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
# .filename.source.r = "f_DSN.Search.read.checkEntity" |> paste0(".source.r"); .subpath=r"()"|>str_replace_all("\\\\","/"); env1$f$f_sourcePath.execute_if_not_sourced(.subpath_filename.source.r = paste0(.subpath,ifelse(.subpath=="","","/"),.filename.source.r))
# if (getwd() != .path4write) warning("getwd() != .path4write  == ") else cat(" getwd() == .path4write == "); dput(.path4write)  
```
  
  
# __________|------  
# @@ REFERENCES) ----  
## install.packages.if_not_already_installed("tidytext")    
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# References:
# 1. tidytext::tidytext::unnest_tokens() - https://cran.r-project.org/web/packages/tidytext/tidytext.pdf
# 2. dplyr::count() - https://cran.r-project.org/web/packages/dplyr/dplyr.pdf
# 3. stringr::str_extract_all() - https://cran.r-project.org/web/packages/stringr/stringr.pdf

install.packages.if_not_already_installed("tidytext")    
```
  
  
# __________|------  
# @@ DATA) example ----  
## :: input_path_file = "Rdev/00_base_program/002_base_encoding_RegEx/FileSample_with_TABLE_OF_CONTENTS.r" ----
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# "Rdev/00_base_program/002_base_encoding_RegEx/FileSample_with_TABLE_OF_CONTENTS.r" |> env1$env.internal.attach$f_file.edit_windows_notepad.or_browseURL()

# input_path_file = rstudioapi::getSourceEditorContext()$path
input_path_file = "Rdev/00_base_program/002_base_encoding_RegEx/FileSample_with_TABLE_OF_CONTENTS.r" |> env1$f$f_path_relative.path_normalized_based_on_path1()  # input_path_file = paste0(env1$path$path1,ifelse(env1$path$path1=="","","/"),input_path_file)

## :: input_vec_chr ====  
input_vec_chr <- readLines(input_path_file, warn = FALSE)  
input_vec_chr |> str()  
input_vec_chr |> env1$env.internal.attach$catLF(trailing_double_spaces = FALSE)  
# > input_vec_chr |> str()  
#  chr [1:37] "##HHHHHHHHHHHHHHHHHH BEGINNING OF TABLE OF CONTENTS HHHHHHHHHHHHHHHHHHHHHH##  " "# TABLE OF CONTENTS ----  " ...
```
  
  
# __________|------  
# @@ START) dev ----  
```{r env0-NoEchoNoResults, echo=FALSE, results="hide"}
env0 = env1
```
  
  
## https://chatgpt.com/c/6772bb5e-3100-800e-a04b-415906b0c197

### \% input_vec_chr |>  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

# input_path_file = rstudioapi::getSourceEditorContext()$path
input_path_file = "Rdev/00_base_program/002_base_encoding_RegEx/FileSample_with_TABLE_OF_CONTENTS.r" |> env1$f$f_path_relative.path_normalized_based_on_path1()  # input_path_file = paste0(env1$path$path1,ifelse(env1$path$path1=="","","/"),input_path_file)
use_tidytext = TRUE
exclude_comments = TRUE

# library(tidytext)    # For tidytext::unnest_tokens()
# library(dplyr)       # For pipe operations and count()
# library(stringr)     # For str_extract_all()

## :: input_vec_chr ====  
input_vec_chr <- readLines(input_path_file, warn = FALSE)  
input_vec_chr |> str()  
input_vec_chr |> env1$env.internal.attach$catLF(trailing_double_spaces = FALSE)  
# > input_vec_chr |> str()  
#  chr [1:37] "##HHHHHHHHHHHHHHHHHH BEGINNING OF TABLE OF CONTENTS HHHHHHHHHHHHHHHHHHHHHH##  " "# TABLE OF CONTENTS ----  " ...
```

#### Remove comments if exclude_comments is TRUE
#### \% |> str_replace_all("#.*", "")
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
# Remove comments if exclude_comments is TRUE
if (exclude_comments) {
    # Use a regular expression to remove anything following '#'
    input_vec_chr <- input_vec_chr |> str_replace_all("#.*", "")  ## |> str_trim()
}
input_vec_chr %>% str
input_vec_chr %>% na_if("") %>% na.omit() %>% str
input_vec_chr %>% na_if("") %>% na.omit() |> env1$env.internal.attach$catLF(trailing_double_spaces = FALSE)
```


#### input_vec_chr.df
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
# Create a tibble with line numbers
input_vec_chr.df <- tibble(
    rowNum = seq_along(input_vec_chr),
    input_vec_chr = input_vec_chr
)
input_vec_chr.df %>% str
input_vec_chr.df %>% filter(input_vec_chr != "")
```


#### \% |> tidytext::unnest_tokens() 
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
input_vec_chr.df %>%
    tidytext::unnest_tokens(
        output = "token_chr",
        input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
        to_lower = FALSE, drop = FALSE, collapse = NULL
    )
```


#### \% |> tidytext::unnest_tokens() |> count()
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
input_vec_chr.df %>%
    tidytext::unnest_tokens(
        output = "token_chr",
        input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
        to_lower = FALSE, drop = FALSE, collapse = NULL
    ) |> 
    count(rowNum, token_chr, sort = TRUE)

input_vec_chr.df %>%
    tidytext::unnest_tokens(
        output = "token_chr",
        input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
        to_lower = FALSE, drop = FALSE, collapse = NULL
    ) |> 
    count(token_chr, sort = TRUE)
```



#### \% |> tidytext::unnest_tokens() |> group_by(token_chr) %>% summarise()
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
input_vec_chr.df %>%
    tidytext::unnest_tokens(
        output = "token_chr",
        input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
        to_lower = FALSE, drop = FALSE, collapse = NULL
    ) |> 
    count(rowNum, token_chr, sort = TRUE)

input_vec_chr.df %>%
    tidytext::unnest_tokens(
        output = "token_chr",
        input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
        to_lower = FALSE, drop = FALSE, collapse = NULL
    ) |> 
    group_by(token_chr) %>% summarise(n = n(), rowNum = paste0(rowNum, collapse = "|")) %>% arrange(desc(n))
```



#### input_vec_chr.df_token_n_rowNum

```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
# Tokenize words using tidytext with a regex for valid object names
input_vec_chr.df_token_n_rowNum <- input_vec_chr.df %>%
    tidytext::unnest_tokens(
        output = "token_chr",
        input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
        to_lower = FALSE, drop = FALSE, collapse = NULL
    ) |> 
    group_by(token_chr) %>% summarise(n = n(), rowNum = paste0(rowNum, collapse = "|")) %>% arrange(desc(n))
input_vec_chr.df_token_n_rowNum
```


#### \$ |> str_extract_all("[a-zA-Z0-9._]+")  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
input_vec_chr |> str_extract_all("[a-zA-Z0-9._]+") %>% str
```


#### rowwise() |> mutate(str_extract_all) |> unnest(token_chr) |> count()  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
# Tokenize words using stringr and str_replace_all-based approach
input_vec_chr.df %>%
    rowwise() %>%  #  to treat each row as a separate group. rowwise() + unnest(cols = ...) can handle a list-of-character-vectors directly.
    mutate(token_chr = list(
        unlist(str_extract_all(input_vec_chr, "\\b[a-zA-Z0-9._]+\\b"))
    )) %>%
    unnest(token_chr)
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
input_vec_chr.df %>%
    rowwise() %>%  #  to treat each row as a separate group. rowwise() + unnest(cols = ...) can handle a list-of-character-vectors directly. 
    mutate(token_chr = list(  unlist(  str_extract_all(input_vec_chr, "[a-zA-Z0-9._]+")  )  )) %>%  # str_extract_all(input_vec_chr, ...) returns list(c("match1", "match2"), c("matchA", "matchB", "matchC"), ...). 
    unnest(token_chr)
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
input_vec_chr.df %>%
    rowwise() %>%  #  to treat each row as a separate group. rowwise() + unnest(cols = ...) can handle a list-of-character-vectors directly. 
    mutate(token_chr = str_extract_all(input_vec_chr, "[a-zA-Z0-9._]+")) %>%   # str_extract_all(input_vec_chr, ...) returns list(c("match1", "match2"), c("matchA", "matchB", "matchC"), ...). 
    unnest(token_chr)
```

###    mutate(token_chr = input_vec_chr %>% map(str_extract_all, "[a-zA-Z0-9._]+")) %>%
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
input_vec_chr.df %>%
    mutate(token_chr = input_vec_chr %>% map(str_extract_all, "[a-zA-Z0-9._]+")) %>%
    unnest(cols = c(token_chr)) %>%
    print(n = 37)
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
input_vec_chr.df %>%
    mutate(token_chr = input_vec_chr %>% map(str_extract_all, "[a-zA-Z0-9._]+")) %>%
    unnest_longer(token_chr)
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
input_vec_chr.df %>%
    mutate(token_chr = input_vec_chr %>% map(str_extract_all, "[a-zA-Z0-9._]+") %>% map(unlist)) %>% 
    unnest(token_chr)
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
input_vec_chr.df %>%
    mutate(token_chr = input_vec_chr %>% map(~unlist(str_extract_all(.x, "[a-zA-Z0-9._]+")))) %>%
    unnest(token_chr)
```


#### rowwise() |> mutate(str_extract_all) |> unnest(token_chr) |> count()  
#### rowwise() |> mutate(str_extract_all) |> unnest(token_chr) |> group_by(token_chr) %>% summarise()  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
input_vec_chr.df %>%
    rowwise() %>%
    mutate(token_chr = str_extract_all(input_vec_chr, "[a-zA-Z0-9._]+")) %>%   # str_extract_all(input_vec_chr, ...) returns list(c("match1", "match2"), c("matchA", "matchB", "matchC"), ...). 
    unnest(token_chr) %>%
    count(token_chr, sort = TRUE)

input_vec_chr.df %>%
    rowwise() %>%
    mutate(token_chr = list(
        unlist(str_extract_all(input_vec_chr, "[a-zA-Z0-9._]+"))
    )) %>%
    unnest(token_chr) %>%
    group_by(token_chr) %>% summarise(n = n(), rowNum = paste0(rowNum, collapse = "|")) %>% arrange(desc(n))
```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
# __________|------  
# @@ SOURCE) ----  
```{r RUN-ALL-CHUNKS-ABOVE, echo=FALSE, results="hide", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
#| RUN ALL CHUNKS ABOVE: CTRL+ALT+SHIFT+P |#
```


```{r .subpath_filename.source.r-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
options(width=120)
options(DEVMODE = TRUE);  # isTRUE(getOption("DEVMODE"))
# .subpath=r"(rstudio-prefs\templates)"|>str_replace_all("\\\\","/")  # Using Raw Strings in R 4.0.0 and Later: The raw string literal, denoted by r"(...)", will not process \ as an escape character.
if(!is.null(env1$path$LastSourceEditorContext.path_filename_ext)) if(env1$path$LastSourceEditorContext.path_filename_ext != "") {.subpath = env1$path$LastSourceEditorContext.path_filename_ext |> dirname(); ".subpath" %>% {cat(.,' = "',get(.),'"  \n', sep="")} }
# if(.subpath!="") utils::browseURL(normalizePath(.subpath))
# .filename.source.r = "default.template" |> paste0(".source.r")
if(!is.null(env1$path$LastSourceEditorContext.path_filename_ext)) if(env1$path$LastSourceEditorContext.path_filename_ext != "") {.sourcename_root = env1$path$LastSourceEditorContext.path_filename_ext |> basename() |> str_replace("\\.(dev|source)\\.(r|Rmd)$"|>regex(ignore_case=TRUE), "") |> str_replace("\\.(r|Rmd)$"|>regex(ignore_case=TRUE),""); ".sourcename_root" %>% {cat(.,' = "',get(.),'"  \n', sep="")} }
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
env1$path$.subpath = .subpath
if(!exists(".sourcename_root") && exists(".filename.source.r")) .sourcename_root = .filename.source.r |> str_replace("\\.source\\.r$", "")
.filename.source.r = .sourcename_root |> paste0(".source.r")
env1$path$.sourcename_root = .sourcename_root
env1$path$.subpath_filename.dev.r = paste0(.subpath,ifelse(.subpath=="","","/"),.sourcename_root,".dev.r")
env1$path$.subpath_filename.dev.Rmd = paste0(.subpath,ifelse(.subpath=="","","/"),.sourcename_root,".dev.Rmd")
env1$path$.subpath_filename.source.r = paste0(.subpath,ifelse(.subpath=="","","/"),.sourcename_root,".source.r")
cat("# ",'.sourcename_root = "',.sourcename_root,'"  \n',
    "#### ",env1$path$.subpath_filename.dev.r, "----  \n",
    "#### ",env1$path$.subpath_filename.dev.Rmd, "----  \n",
    "#### ",env1$path$.subpath_filename.source.r, "----  \n",
    '# # source(paste0(env1$path$source_base,"/","',env1$path$.subpath_filename.source.r,'"))', "  \n",
    '# # if(!file.exists("',env1$path$source_base_local,"/",env1$path$.subpath_filename.dev.r,'")) download.file(url = "https://raw.githubusercontent.com/mkim0710/tidystat/master/rstudio-prefs/templates/default.R", destfile = "',env1$path$source_base_local,"/",env1$path$.subpath_filename.dev.r,'")', "  \n",
    '# # if(!file.exists("',env1$path$source_base_local,"/",env1$path$.subpath_filename.dev.Rmd,'")) download.file(url = "https://raw.githubusercontent.com/mkim0710/tidystat/master/rstudio-prefs/templates/templates-00env1.minimum.Rmd", destfile = "',env1$path$source_base_local,"/",env1$path$.subpath_filename.dev.Rmd,'")', "  \n",
    '# # if(!file.exists("',env1$path$source_base_local,"/",env1$path$.subpath_filename.source.r,'")) download.file(url = "https://raw.githubusercontent.com/mkim0710/tidystat/master/rstudio-prefs/templates/default.R", destfile = "',env1$path$source_base_local,"/",env1$path$.subpath_filename.source.r,'")', "  \n",
    '# file.edit("',env1$path$source_base_local,"/",env1$path$.subpath_filename.dev.r,'"); if(!is.null(env1$path$LastSourceEditorContext.path_filename_ext)) if(env1$path$LastSourceEditorContext.path_filename_ext != "") file.edit(paste0(env1$path$path1,"/",env1$path$LastSourceEditorContext.path_filename_ext));', "  \n",
    '# file.edit("',env1$path$source_base_local,"/",env1$path$.subpath_filename.dev.Rmd,'"); if(!is.null(env1$path$LastSourceEditorContext.path_filename_ext)) if(env1$path$LastSourceEditorContext.path_filename_ext != "") file.edit(paste0(env1$path$path1,"/",env1$path$LastSourceEditorContext.path_filename_ext));', "  \n",
    '# file.edit("',env1$path$source_base_local,"/",env1$path$.subpath_filename.source.r,'"); if(!is.null(env1$path$LastSourceEditorContext.path_filename_ext)) if(env1$path$LastSourceEditorContext.path_filename_ext != "") file.edit(paste0(env1$path$path1,"/",env1$path$LastSourceEditorContext.path_filename_ext));', "  \n",
    sep="")
# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
# # \% source( file.path(env1$path$source_base,.subpath_filename.source.r) ) ----  
# env1$f$f_sourcePath.execute_if_not_sourced(.subpath_filename.source.r = paste0(.subpath,ifelse(.subpath=="","","/"),.filename.source.r))
```
  
  
# __________|------  
# @@ START) function ----  

## https://chatgpt.com/c/6772bb5e-3100-800e-a04b-415906b0c197
## https://chatgpt.com/c/6773c8bd-cc78-800e-b7a2-b5593ab4b673

## :: f_vec_chr.df_token_n_rowNum = function() -dev -pending  
### \% |> env1$f$f_vec_chr.df_token_n_rowNum()  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
## ->> Now included in env1$env.internal.source.r ----

##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
## :: f_vec_chr.df_token_n_rowNum = function() ====
## Rdev/00_base_program/002_base_encoding_RegEx/f_vec_chr.df_token_n_rowNum.dev.Rmd
.tmp$env1_subenv_name = "f"
.tmp$objectname = "f_vec_chr.df_token_n_rowNum" 
env1[[.tmp$env1_subenv_name]][[.tmp$objectname]] = function(
    input_vec_chr = rstudioapi::getSourceEditorContext()$path |> readLines(warn = FALSE),
    use_tidytext = TRUE,
    exclude_comments = TRUE,
    VERBOSE = isTRUE(getOption("verbose"))
) {
    # Load libraries inside function scope (generally not recommended in production)
    # library(tidytext)    # For tidytext::unnest_tokens()
    # library(dplyr)       # For pipe operations and count()
    # library(stringr)     # For str_extract_all()
    
    # 3. Remove comments if exclude_comments is TRUE
    if (isTRUE(exclude_comments)) {
        input_vec_chr <- input_vec_chr |> str_replace_all("#.*", "")  ## |> str_trim()
    }
    
    # 4. Create a tibble with integer line numbers
    input_vec_chr.df <- tibble(
        rowNum = as.integer(seq_along(input_vec_chr)),
        input_vec_chr = input_vec_chr
    )
    
    # Optional debug print
    if (isTRUE(VERBOSE)) {
        cat("<VERBOSE> str(input_vec_chr.df)  \n")
        str(input_vec_chr.df)
    }
    
    # 5. Tokenize words
    if (isTRUE(use_tidytext)) {
        # Approach 1: Tidytext
        # my_tokenize <- function(text_vec) {
        #     # Return a list of character vectors
        #     # containing your desired tokenization logic
        #     stringr::str_extract_all(text_vec, "[a-zA-Z0-9._]+")
        # }
        # input_vec_chr.df_token_n_rowNum <- input_vec_chr.df %>%
        #     tidytext::unnest_tokens(
        #         output = "token_chr",
        #         input = input_vec_chr,
        #         token = my_tokenize, # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
        #         to_lower = FALSE, 
        #         drop = FALSE, 
        #         collapse = NULL
        #     ) %>%
        #     group_by(token_chr) %>% summarise(n = n(), rowNum = paste0(rowNum, collapse = "|")) %>% arrange(desc(n))
        
        input_vec_chr.df_token_n_rowNum <- input_vec_chr.df %>%
            tidytext::unnest_tokens(
                output = "token_chr",
                input = input_vec_chr,
                token = "regex",  # Unit for tokenizing, or a custom tokenizing function. Built-in options are "words" (default), "characters", "character_shingles", "ngrams", "skip_ngrams", "sentences", "lines", "paragraphs", "regex", and "ptb" (Penn Treebank). If a function, should take a character vector and return a list of character vectors of the same length.
                pattern = "[^a-zA-Z0-9._]+",  # Split by non-alphanumeric characters, except dot and underscore.
                to_lower = FALSE, drop = FALSE, collapse = NULL
            ) %>%
            group_by(token_chr) %>% summarise(n = n(), rowNum = paste0(rowNum, collapse = "|")) %>% arrange(desc(n))
        
    } else {
        # Approach 2: Stringr / gsub approach
        input_vec_chr.df_token_n_rowNum <- input_vec_chr.df %>%
            # mutate(token_chr = input_vec_chr %>% map(str_extract_all, "[a-zA-Z0-9._]+") %>% map(unlist)) %>% 
            # mutate(token_chr = input_vec_chr %>% map(~unlist(str_extract_all(.x, "[a-zA-Z0-9._]+")))) %>%
            rowwise() %>%
            # mutate(token_chr = input_vec_chr %>% str_extract_all("\\b[a-zA-Z0-9._]+\\b")) %>%    # \\b (word boundary) in most regex engines is defined to match the transition between a “word character” (usually [A-Za-z0-9_]) and a “non-word” character (or line boundary). A leading period (.) is not included in the standard “word character” set, so .tmp might not be recognized as one complete token at a word boundary.
            mutate(token_chr = input_vec_chr %>% str_extract_all("[a-zA-Z0-9._]+")) %>% 
            unnest(cols = c(token_chr)) %>%
            group_by(token_chr) %>% summarise(n = n(), rowNum = paste0(rowNum, collapse = "|")) %>% arrange(desc(n))
    }
    
    # Another optional debug print
    if (isTRUE(VERBOSE)) {
        cat("<VERBOSE> str(input_vec_chr.df_token_n_rowNum)  \n")
        str(input_vec_chr.df_token_n_rowNum)
    }
    
    # 6. Return result
    return(input_vec_chr.df_token_n_rowNum)
}
```


## :: f_file.df_token_n_rowNum = function() -dev -pending  
### \% |> env1$f$f_file.df_token_n_rowNum()  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
## ->> Now included in env1$env.internal.source.r ----

##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
## :: f_file.df_token_n_rowNum = function() ====
## Rdev/00_base_program/002_base_encoding_RegEx/f_vec_chr.df_token_n_rowNum.dev.Rmd
.tmp$env1_subenv_name = "f"
.tmp$objectname = "f_file.df_token_n_rowNum" 
env1[[.tmp$env1_subenv_name]][[.tmp$objectname]] = function(
    input_path_file = rstudioapi::getSourceEditorContext()$path,
    use_tidytext = TRUE,
    exclude_comments = TRUE,
    VERBOSE = isTRUE(getOption("verbose"))
) {
    # Load libraries inside function scope (generally not recommended in production)
    # library(tidytext)    # For tidytext::unnest_tokens()
    # library(dplyr)       # For pipe operations and count()
    # library(stringr)     # For str_extract_all()
    
    # 1. Check if file exists
    if (!file.exists(input_path_file)) {
        stop("File does not exist: ", input_path_file)
    }
    
    # 2. Read the source code file into a character vector
    input_vec_chr <- readLines(input_path_file, warn = FALSE)
    
    input_vec_chr.df_token_n_rowNum = env1$f$f_vec_chr.df_token_n_rowNum(
        input_vec_chr = input_vec_chr,
        use_tidytext = use_tidytext,
        exclude_comments = exclude_comments,
        VERBOSE = VERBOSE
    )
    
    # 6. Return result
    return(input_vec_chr.df_token_n_rowNum)
}

###############################################################################
# Example Usage
###############################################################################
# Suppose you have a small health-data-related R script named "exampleHealthData.R"
# that looks like this:
#
# # This script processes CDC data
# cdc_data <- read.csv("CDC_data.csv")
# summary(cdc_data)
# who_data <- read.csv("WHO_data.csv")  # Another line referencing WHO data
# mean(who_data$some_measure)
#
# Let us demonstrate how to call f_file.df_token_n_rowNum on that file below.

# Replace with your actual script path
example_path_file <- "Rdev/00_base_program/002_base_encoding_RegEx/FileSample_with_TABLE_OF_CONTENTS.r" |> env1$f$f_path_relative.path_normalized_based_on_path1()  # input_path_file = paste0(env1$path$path1,ifelse(env1$path$path1=="","","/"),input_path_file)

# 1) Using tidytext approach
tidytextTokens_df <- env1$f$f_file.df_token_n_rowNum(
    input_path_file = example_path_file,
    use_tidytext    = TRUE,
    exclude_comments = TRUE,
    VERBOSE     = TRUE
)

# 2) Using stringr/gsub approach
stringrTokens_df <- env1$f$f_file.df_token_n_rowNum(
    input_path_file = example_path_file,
    use_tidytext    = FALSE,
    exclude_comments = TRUE,
    VERBOSE     = TRUE
)

# Print final results
cat("\n=== Word Frequencies Using Tidytext ===\n")
print(tidytextTokens_df)

cat("\n=== Word Frequencies Using Stringr ===\n")
print(stringrTokens_df)


```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
  
# __________|------  
# @@ END ----  
```{r END-NoEvalNoEchoNoMsgNoResults, eval=FALSE, echo=FALSE, warning=TRUE, message=NA, results="hide", collapse=TRUE, paged.print=FALSE}
##________________________________________________________________________________  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
##++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++  
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
##________________________________________________________________________________  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# @@ END ----  
cat("    ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::    \n")
cat("    [][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][]    \n")
cat("    {}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}    \n")
cat("    ()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()    \n")
cat("    <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>    \n")
cat("    HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH    \n")
cat("    OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO    \n")
cat("    XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX    \n")
cat("    VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV    \n")
cat("    WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW    \n")
cat("    -|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|    \n")
cat("    ________________________________________________________________________    \n")
cat("    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n")
cat("    ************************************************************************    \n")
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
cat("    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n")
```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```

  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```

  
  
```{r createBACKUP, eval=TRUE, include=FALSE}
if (Sys.getenv("PARENT_RENDERING") != "YES") {
    # if (Sys.info()["sysname"] == "Windows") {
        env1$env.internal.attach$f_filename_ext.createBACKUP(BACKUP_from_path_filename_ext = rstudioapi::getSourceEditorContext()$path|>str_replace("\\.([[:alnum:]]+)$",".Rmd"), .BACKUP_to_path="-BACKUP", timeFormat="%y%m%d_%H", overwrite=TRUE)
        # env1$env.internal.attach$f_filename_ext.createBACKUP(BACKUP_from_path_filename_ext = rstudioapi::getSourceEditorContext()$path|>str_replace("\\.([[:alnum:]]+)$",".nb.html"), .BACKUP_to_path="-BACKUP", timeFormat="%y%m%d_%H", overwrite=TRUE)
    # }
}
```
  
  
```{r gitCheckout-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
env1$source[[basename(rstudioapi::getSourceEditorContext()$path)]] = rstudioapi::getSourceEditorContext()$path
env1$path$LastSourceEditorContext.path_filename.nb.html = env1$path$LastSourceEditorContext.path_filename_ext |> str_replace("\\.([[:alnum:]]+)$",".nb.html")
if (Sys.info()["sysname"] == "Windows" && Sys.getenv("PARENT_RENDERING") != "YES") { paste0('ping -n 5 127.0.0.1 > nul & "C:/Program Files (x86)/Microsoft/Edge/Application/msedge_proxy.exe" --app="',env1$path$LastSourceEditorContext.path_filename.nb.html %>% {paste0(env1$path$path1,"/",.)}|>normalizePath(winslash="/",mustWork=NA),'"') |> shell(wait=FALSE) } # else { browseURL(env1$path$LastSourceEditorContext.path_filename.nb.html %>% {paste0(env1$path$path1,"/",.)}) }
# paste0("https://github.com/mkim0710/",basename(getwd()),"/blob/main/",env1$path$LastSourceEditorContext.path_filename_ext) %>% paste0('"C:/Program Files (x86)/Microsoft/Edge/Application/msedge_proxy.exe" --app="',.,'"') |> system(intern=TRUE)
paste0("https://github.com/mkim0710/",basename(getwd()),"/blob/main/",env1$path$LastSourceEditorContext.path_filename_ext) %>% paste0('"C:/Program Files (x86)/Microsoft/Edge/Application/msedge_proxy.exe" --app="',.,'"') %>% paste0("'",.,"' |> system(intern=TRUE)") |> cat("  \n", sep="")
# paste0("https://github.com/mkim0710/",basename(getwd()),"/commits/main/",env1$path$LastSourceEditorContext.path_filename_ext) %>% paste0('"C:/Program Files (x86)/Microsoft/Edge/Application/msedge_proxy.exe" --app="',.,'"') |> system(intern=TRUE)
paste0("https://github.com/mkim0710/",basename(getwd()),"/commits/main/",env1$path$LastSourceEditorContext.path_filename_ext)  %>% paste0('"C:/Program Files (x86)/Microsoft/Edge/Application/msedge_proxy.exe" --app="',.,'"') %>% paste0("'",.,"' |> system(intern=TRUE)") |> cat("  \n", sep="")
cat("* To revert to the last commited file, run the following terminal command:  \n")
paste0( "git checkout -- ",shQuote(paste0(env1$path$path1,"/",env1$path$LastSourceEditorContext.path_filename_ext)) ) |> deparse() |> cat(" |> system(intern=TRUE)  \n", sep="")
paste0( "git checkout -- ",shQuote(paste0(env1$path$path1,"/",env1$path$LastSourceEditorContext.path_filename.nb.html)) ) |> deparse() |> cat(" |> system(intern=TRUE)  \n", sep="")
```
  
  
