---
# https://forum.posit.co/t/when-to-use-yaml-vs-when-to-use-setup-code-chunk/56169/
title: "`r params$doc_title`"
author: "MHKim"
date: "`r Sys.setlocale('LC_ALL', 'en_US.utf8'); format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    md_extensions: -smart
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_sections: false
    code_folding: none
    df_print: tibble
    highlight: textmate
    fig_width: 10
    fig_height: 6
  html_document:
    md_extensions: -smart
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_sections: false
    df_print: tibble
    code_folding: none
    highlight: textmate
    fig_width: 10
    fig_height: 6
  pdf_document:
    md_extensions: -smart
    toc: yes
    toc_depth: 6
    fig_width: 10
    fig_height: 6
    latex_engine: xelatex  # mainfont, sansfont, monofont, mathfont works only with xelatex and lualatex, but not pdflatex
    keep_tex: true
  word_document:
    md_extensions: -smart
    toc: yes
    toc_depth: 6
    fig_width: 9
    fig_height: 6
# documentclass: scrartcl  # https://pandoc.org/MANUAL.html#variables-for-latex
# classoption: fontsize=9pt 
geometry: portrait, a3paper, margin=20mm # https://bookdown.org/yihui/rmarkdown/pdf-document.html#latex-options
# fontsize: 12pt
header-includes: 
  - \usepackage{fontspec}
  - \newcommand{\setfallbackfont}[4]{
      \IfFontExistsTF{#2}
        {#1{#2}}
        {\IfFontExistsTF{#3}
          {#1{#3}}
          {#1{#4}}}}
  # - \setfallbackfont{\setmainfont}{Roboto Condensed}{Noto Sans Condensed}{Arial Narrow}
  # - \setfallbackfont{\setsansfont}{Roboto Condensed}{Noto Sans Condensed}{Arial Narrow}
  - \setfallbackfont{\setmainfont}{Roboto}{Noto Sans}{Arial}
  - \setfallbackfont{\setsansfont}{Roboto}{Noto Sans}{Arial}
  - \setfallbackfont{\setmonofont}{Cascadia Code SemiBold}{Cascadia Code}{Fira Code}
  - \usepackage[hangul]{kotex}
  # - \setfallbackfont{\setmainhangulfont}{NanumGothic}{HCR Dotum LVT}{Malgun Gothic}
  # - \setfallbackfont{\setsanshangulfont}{NanumGothic}{HCR Dotum LVT}{Malgun Gothic}
  # - \setfallbackfont{\setmonohangulfont}{D2Coding}{NanumGothicCoding}{NanumGothic}
params:
  doc_title: !r basename(rstudioapi::getSourceEditorContext()$path)
# https://stackoverflow.com/questions/55751815/r-markdown-difference-between-parameters-and-variables
# ?rmarkdown::html_document
---
<!-- https://stackoverflow.com/questions/28480625/r-knitr-markown-setting-html-page-width -->
<style type="text/css">
.main-content, .toc {max-width: 785px; margin: 0 auto; font-size: 1rem;} /* A4: 21cm x 29.7cm = 8.27in x 11.69in; 8.27in x 96px/in â‰ˆ 793px */
html { font-size: 12px; }
body { font-size: 12px; font-family: 'Roboto Condensed', 'Noto Sans Condensed', 'Open Sans Condensed', 'Source Sans 3', 'Arial Narrow', Helvetica, sans-serif; }
h1.title { font-size: 28px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 14px; margin-bottom: 0; color: Navy; }
h1 { font-size: 24px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 12px; margin-bottom: 0; color: Navy; }
h2 { font-size: 21px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 11px; margin-bottom: 0; color: Navy; }
h3 { font-size: 18px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 9px; margin-bottom: 0; color: Navy; }
h4 { font-size: 16px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 8px; margin-bottom: 0; color: Navy; }
h5 { font-size: 14px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 7px; margin-bottom: 0; color: Navy; }
h6 { font-size: 12px; font-family: 'Roboto Serif', 'Noto Serif', 'Source Serif 4', serif; line-height: 1.1; margin-top: 6px; margin-bottom: 0; color: Navy; }
table, td, th, figure, figcaption { font-size: 10px; font-family: 'Roboto Condensed', 'Noto Sans Condensed', 'Open Sans Condensed', 'Source Sans 3', 'Arial Narrow', Helvetica, sans-serif; line-height: 1.1; margin-top: 5px; margin-bottom: 0; }
code { font-size: 11px; font-family: 'Cascadia Code SemiBold', 'Cascadia Code', 'Fira Code', Consolas, 'Source Code Pro', monospace; line-height: 1.1; margin-top: 6px; margin-bottom: 0; color: DimGray; background-color: Snow; }
pre { font-size: 11px; font-family: 'Cascadia Code SemiBold', 'Cascadia Code', 'Fira Code', Consolas, 'Source Code Pro', monospace; line-height: 1.1; margin-top: 6px; margin-bottom: 0; color: DimGray; background-color: Snow; }
</style>
  
<!-- font-size: 0.9em; /* 90% of inherited font size */ -->
  
<!-- Body text (body): The default font size is typically 16 pixels. -->
<!-- Paragraphs (p): Inherit the body's font size, so also typically 16 pixels. -->
<!-- List items (li): Inherit the body's font size, generally 16 pixels. -->
<!-- Headings (h1 to h6): The default sizes decrease with each level. For example: -->
<!-- h1: Typically around 32 pixels. -->
<!-- h2: Often around 24 pixels. -->
<!-- h3: Commonly around 18.72 pixels. -->
<!-- h4: Usually about 16 pixels. -->
<!-- h5: Generally around 13.28 pixels. -->
<!-- h6: Often about 10.72 pixels. -->
<!-- Blockquotes (blockquote): Usually inherit the body's font size, around 16 pixels. -->
<!-- Tables (table), table cells (td, th): Typically inherit the body's font size, so around 16 pixels. -->
<!-- Figures (figure) and figure captions (figcaption): Generally inherit the body's font size, so about 16 pixels. -->
<!-- 1: Approximately 8 pixels. -->
<!-- 2: Approximately 10 pixels. -->
<!-- 3: Approximately 12 pixels (this was often considered the default size). -->
<!-- 4: Approximately 14 pixels. -->
<!-- 5: Approximately 18 pixels. -->
<!-- 6: Approximately 24 pixels. -->
# __________|------  
<!-- {r Rstudio-RMarkDown-Shortcuts, eval=FALSE, include=FALSE} -->
<!-- ##### Rstudio RMarkDown Shortcuts -->
<!-- https://support.posit.co/hc/en-us/articles/200711853-Keyboard-Shortcuts-in-the-RStudio-IDE   -->
<!-- https://bookdown.org/yihui/rmarkdown-cookbook/rstudio-shortcuts.html   -->
<!-- Insert R chunk	Ctrl+Alt+I	Command+Option+I   -->
<!-- Preview HTML	Ctrl+Shift+K	Command+Shift+K   -->
<!-- Run all chunks above	Ctrl+Alt+P	Command+Option+P   -->
<!-- Run current chunk	Ctrl+Alt+C	Command+Option+C   -->
<!-- Run current chunk	Ctrl+Shift+Enter	Command+Shift+Enter   -->
<!-- Run next chunk	Ctrl+Alt+N	Command+Option+N   -->
<!-- Run all chunks	Ctrl+Alt+R	Command+Option+R   -->
<!-- Go to next chunk/title	Ctrl+PgDown	Command+PgDown   -->
<!-- Go to previous chunk/title	Ctrl+PgUp	Command+PgUp   -->
<!-- Show/hide document outline	Ctrl+Shift+O	Command+Shift+O   -->
<!-- F7 spell-check your document.   -->
<!-- Restart the R session   Ctrl + Alt + F10 (or Command + Option + F10 on macOS).   -->
<!--    -->
<!-- *** Caution: @ # \$ \% * \\ ***  -->

  
```{r setup, echo=FALSE, results="hide"}
## Cf) {r setup, eval=TRUE, include=FALSE}
if(Sys.info()["sysname"] == "Windows") Sys.setlocale("LC_ALL", "en_US.UTF-8")  # Note that setting category "LC_ALL" sets only categories "LC_COLLATE", "LC_CTYPE", "LC_MONETARY" and "LC_TIME".
# Sys.setlocale("LC_MESSAGES", "en_US.utf8")  # Note that the LANGUAGE environment variable has precedence over "LC_MESSAGES" in selecting the language for message translation on most R platforms.  # LC_MESSAGES does not exist in Windows
Sys.setenv(LANGUAGE="en_US");  # Sys.getenv("LANGUAGE");    # Note that the LANGUAGE environment variable has precedence over "LC_MESSAGES" in selecting the language for message translation on most R platforms.
# str(knitr::opts_chunk$get())
# cat(deparse(knitr::opts_chunk$get(), width.cutoff=120), "  \n", sep="")
# list(eval=TRUE, echo=TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = "##",     highlight = TRUE, size = "normalsize", background = "#F7F7F7", strip.white = structure(TRUE, class = "AsIs"), cache = FALSE,     cache.path = "cache/", cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, autodep = FALSE, cache.rebuild = FALSE,     fig.keep = "high", fig.show = "asis", fig.align = "default", fig.path = "figure/", dev = NULL, dev.args = NULL, dpi = 72,     fig.ext = NULL, fig.width=7, fig.height=7, fig.env = "figure", fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:",     fig.subcap = NULL, fig.pos = "", out.width=NULL, out.height=NULL, out.extra = NULL, fig.retina = 1, external = TRUE,     sanitize = FALSE, interval = 1, aniopts = "controls,loop", warning = TRUE, error = TRUE, message = TRUE, render = NULL,     ref.label = NULL, child = NULL, engine = "R", split = FALSE, include = TRUE, purl = TRUE)
knitr::opts_chunk$set(
    eval=TRUE, echo=FALSE, results="markup", collapse=TRUE, # In Rstudio Notebook Source Pane & nb.HTML, results="hold" does not work
    comment="#", fig.width=10, fig.height=6, # In Rstudio Notebook Source Pane & nb.HTML, comment="##" does not work?
    warning=TRUE, message=TRUE, include=TRUE, 
    error=FALSE,  # error=TRUE: show the errors without stopping R; error=FALSE: stop on error
    tidy.opts=list(width.cutoff=120), tidy=FALSE, 
    R.options = list(width=120), paged.print=FALSE
) 
# knitr::opts_chunk$set(message=TRUE) & {r, results="hide"} -> message shown in Rstudio Notebook Source Pane & knitted HTML, but not in Preview nb.HTML?!
# knitr::opts_chunk$set(message=FALSE) & {r, message=TRUE, results="hide"} -> message shown in Rstudio Notebook Source Pane & knitted HTML, but not in Preview nb.HTML?!
# *** results="hide": results shown only on Rstudio Notebook Source Pane, but not in nb.HTML nor knitted HTML
knitr::opts_knit$set(global.par = TRUE)


## Cf) {r loadPackages-NoEchoHideResults, echo=FALSE, results="hide"}
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# env1$f$MH_shortcuts()
#| ------------------------- < To be covered at .Rprofile > --------------------- |#  
if(!exists("env1", envir=.GlobalEnv)) {  message('> source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")')  ;  source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")  ;  .First()  }  
if(!".Rprofile" %in% names(.GlobalEnv$env1$source)) {  message('> source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")')  ;  source("https://raw.githubusercontent.com/mkim0710/tidystat/master/.Rprofile")  ;  .First()  }  
##________________________________________________________________________________  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
env1$info$options.width = getOption("width"); cat('\tgetOption("width") == ', env1$info$options.width, "  \n", sep="")
#   
## Cf) {r env1-Info-NoEchoHideResults, echo=FALSE, results="hide"}
# https://yihui.org/knitr/options/#package-options
env1$info$info_software_versions = env1$env.internal.attach$get_software_versions(library_names = c("tidyverse", "dplyr", "ggplot2", "purrr", "stringr", "stats","survival"))
# str(env1$info$info_software_versions)


###### env1\$info\$DocumentTitle1 ----  
# ```{r env1-DocumentTitle1-NoEchoHideResults, echo=FALSE, results="hide"}
env1$info$DocumentTitle0 = paste0("00env1.minimum","-",basename(getwd()))
env1$info$DocumentTitle1 = paste0(env1$info$DocumentTitle0,"@", ifelse(grepl("MacBook-Pro", Sys.info()["nodename"]), "MBP", Sys.info()["nodename"]))
cat(env1$info$DocumentTitle0,"-",format(Sys.time(),"%y%m%d"), "\n", 
    env1$info$DocumentTitle0,"-",format(Sys.time(),"%y%m%d"),".Rmd", "\n", 
    env1$info$DocumentTitle0,"-dev",format(Sys.time(),"%y%m%d"),".Rmd", "\n", 
    env1$info$DocumentTitle0,"-clean",format(Sys.time(),"%y%m%d"),".Rmd", "\n", 
    sep="")
```
  
  
```{r env1-Path-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
###### env1\$path ----  
# cat(" getwd() == "); dput(getwd())  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
### env1\$path\$LastSourceEditorContext.path_FileNameExt ====  
# *** Caution) In Rstudio Notebook, the path of the running Rmd file is set as the working directory~!!!
# .tmp$LastSourceEditorContext.path_FileNameExt = rstudioapi::getSourceEditorContext()$path |> normalizePath(winslash="/",mustWork=NA)    # Caution) not a relative path~!  
# env1$path$LastSourceEditorContext.path_FileNameExt = rstudioapi::getSourceEditorContext()$path |> normalizePath(winslash="/",mustWork=NA) |> str_replace(fixed(env1$path$path1|>normalizePath(winslash="/",mustWork=NA)), "") |> str_replace("^/", "")
env1$path$LastSourceEditorContext.path_FileNameExt = rstudioapi::getSourceEditorContext()$path |> normalizePath(winslash="/",mustWork=NA)    # Caution) Not using a relative path~!
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# env1$path$project_base = "Rproject_HEALS0215"
# env1$path$data_suffix = "_01"
# # env1$path$data_suffix = ""
# env1$path$project_suffix = "GJ3"
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
# env1$path$path4read = file.path(env1$path$path0, paste0(env1$path$project_base, env1$path$data_suffix))
# env1$path$path4write = file.path(env1$path$path4read, paste0(env1$path$project_base, env1$path$data_suffix, env1$path$project_suffix))
env1$path$path4read = ifelse(is.na(env1$path$path1), getwd(), env1$path$path1)
env1$path$path4write = getwd()
.path4read  = env1$path$path4read
.path4write = env1$path$path4write
# cat(" > str(env1$path)\n"); str(env1$path, max.level = 1, give.attr = F)  

## @ env1 |> as.list() |> str(max.level = 2, give.attr = FALSE) ----  
"ls(all.names = TRUE, envir = .GlobalEnv) |> set_names() |> map(get) |> str(max.level = 1, give.attr = FALSE)" |> env1$f$f_CodeText.ECHO(EXECUTE = TRUE, deparse_cat = FALSE, LinePrefix4CodeText = "> ", LinePrefix4Output = "")
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
".tmp |> str(max.level = 1, give.attr = FALSE)" |> env1$f$f_CodeText.ECHO(EXECUTE = TRUE, deparse_cat = FALSE, LinePrefix4CodeText = "> ", LinePrefix4Output = "")
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
"env1 |> as.list() |> env1$f$f_list.str_by_element(max.level = 2, give.attr = FALSE)" |> env1$f$f_CodeText.ECHO(EXECUTE = TRUE, deparse_cat = FALSE, LinePrefix4CodeText = "> ", LinePrefix4Output = "")
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
# .FileName.source.r = "f_DSname.Search.read.checkEntity" |> paste0("-source.R"); .RelativeSubPath=r"(R)"|>str_replace_all("\\\\","/"); env1$f$f_sourcePath.execute_if_not_sourced(.RelativeSubPath_FileName.source.r = list(.RelativeSubPath, .FileName.source.r) %>% {.[nzchar(.)]} %>% c(fsep = "/") %>% {do.call(file.path, .)})
# if (getwd() != .path4write) warning("getwd() != .path4write  == ") else cat(" getwd() == .path4write == "); dput(.path4write)  
```
  
  
# __________|------  
# ã€šã€› DATA) example ----  
## \$ ADS_time2event =  ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
.packagename = "tidyverse"; if (!paste0("package:",.packagename) %in% search()) {library(.packagename, character.only = TRUE)}
# suppressPackageStartupMessages(library(survival))
for(.packagename in c("survminer")) {if(!require(.packagename,character.only=TRUE)) install.packages(.packagename)  ;  library(.packagename,character.only=TRUE)}  
# ?survival::lung
.objectname = DSN = "ADS_time2event"
assign(
    DSN, 
    survival::lung |> as_tibble() |> mutate(event = as.logical(status-1), Group = c("Male", "Female")[sex] |> as.factor(), StudyPopulation = time >= 30) |>
        # dplyr::select(-status, -sex)
        dplyr::select(-status)
)
ADS_time2event %>% {cat(" > ",deparse(substitute(.))," |> as_tibble() |> print()","  \n", sep=""); print(as_tibble(.))}
```
  
  
### :: df_5vars_10obs ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# Manually create a dataset
df_5vars_10obs <- data.frame(
    Group = rep(c("Group1", "Group2"), each = 5),
    Var1 = c(2.5, 3.0, 2.8, 2.9, 3.1, 3.6, 3.7, 3.5, 3.8, 3.9),
    Var2 = c(7.1, 7.3, 7.2, 7.4, 7.5, 6.8, 6.9, 7.0, 6.7, 6.6),
    Var3 = c(15, 16, 15, 14, 15, 18, 17, 19, 18, 17),
    Var4 = c(0.5, 0.6, 0.55, 0.58, 0.57, 0.65, 0.66, 0.64, 0.67, 0.68),
    Var5 = c(100, 105, 102, 101, 103, 110, 112, 111, 113, 114)
)

# Display the dataset
print(df_5vars_10obs)
```
  
  
### :: df_numeric5_categorical2 ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
df_numeric5_categorical2 = 
    structure(list(group_variable = c("A", "A", "A", "B", "B", "B", "C", "C", "C"), numeric_var1 = c(10L, 12L, 11L, 20L, 22L, 21L, 30L, 32L, 31L), numeric_var2 = c(100L, 102L, 101L, 200L, 202L, 201L, 300L, 302L, 301L), numeric_var3 = c(5, 6, 5.5, 10, 11, 10.5, 15, 16, 15.5), numeric_var4 = c(25, 26, 25.5, 50, 51, 50.5, 75, 76, 75.5), numeric_var5 = c(2, 2.2, 2.1, 4, 4.2, 4.1, 6, 6.2, 6.1), categorical_var1 = c("X", "Y", "X", "Y", "Z", "Y", "Z", "X", "Z"), categorical_var2 = c("M", "N", "M", "N", "O",  "N", "O", "M", "O")), class = "data.frame", row.names = c(NA, -9L))
df_numeric5_categorical2
```
  
  
## :: titanic_train() ----  
### :: titanic_data() ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
for(.packagename in c("titanic")) {if(!require(.packagename,character.only=TRUE)) install.packages(.packagename)  ;  library(.packagename,character.only=TRUE)}  

# Load the Titanic dataset
data("titanic_train")

# View the first few rows
titanic_train |> str(max.level = 2, give.attr = TRUE)
titanic_train %>% as_tibble

# Select relevant variables
titanic_data <- titanic_train %>%
    select(Survived, Pclass, Sex, Age, Fare) %>% as_tibble

# Handle missing values by removing rows with NA
titanic_data <- na.omit(titanic_data)

# Convert 'Survived' and 'Sex' to factors
titanic_data$Survived <- factor(titanic_data$Survived)
titanic_data$Sex <- factor(titanic_data$Sex)
titanic_data |> str(max.level = 2, give.attr = TRUE)
titanic_data %>% as_tibble
```
  
  
## :: JK02ID.CCW.MIN_Date.ge365.MDD.EndTime.i.recode.bin.4c.EndTimeP.NA_rm.CC69.agg4.4069AgeNum.i2007.1.1 = ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# # Define variable names
# varnames <- c(
#   "EndTime.is.Case.confirm.365", "EndTime", "AgeDecade", "Female", "Income",
#   "DisabilityGrade", "AcquiredHypothyroidism", "AdjustmentDisorder", "Anemia",
#   "Anxiety", "Arthritis", "AtrialFibrillation", "BenignProstatic",
#   "BrainInjury", "Cataract", "ChronicKidney", "Diabetes", "Dysthymia",
#   "Epilepsy", "Fibromyalgia_Pain_Fatigue", "Glaucoma", "HearingImpairment",
#   "HeartFailure", "Hyperlipidemia", "Hypertension", "IschemicHeart",
#   "Migraine_ChronicHeadache", "MobilityImpairments", "Osteoporosis",
#   "PelvicFx", "PersonalityDisorders", "SpinalCordInjury", "StrokeTIA",
#   "AlzheimerDementia", "LiverDisease", "ObstructiveLungDisease",
#   "CancerSurvivors"
# )
# 
# # Function to load and preprocess data
# load_preprocess_data <- function(file_path, varnames, is_test = FALSE) {
#   data <- readRDS(file_path)[varnames] %>%
#     mutate(EndTime = as.numeric(EndTime))
#   
#   if (is_test) {
#     data <- data %>% mutate(testset = TRUE)
#   }
#   
#   return(as_tibble(data))
# }
# 
# # Load training and testing datasets
# train_file <- "JK02ID.CCW.MIN_Date.ge365.MDD.EndTime.i.recode.bin.4c.EndTimeP.NA_rm.CC69.agg4.4069AgeNum.i2007.1.1.rda"
# test_file <- "JK02ID.CCW.MIN_Date.ge365.MDD.EndTime.i.recode.bin.4test.EndTimeP.NA_rm.CC69.agg4.4069AgeNum.i2007.1.1.rda"
# 
# TheTrainSet <- load_preprocess_data(train_file, varnames, is_test = FALSE)
# TheTestSet  <- load_preprocess_data(test_file, varnames, is_test = TRUE)
```
  
  
## :: example_train_data() ----  
### :: example_test_data() ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# Load necessary libraries
library(tidyverse)
library(survival)

# Create non-random example dataset
example_train_data <- tibble(
  EndTime.is.Case.confirm.365 = c(1, 1, 0, 0, 1, 0),
  EndTime = c(2, 3, 5, 10, 7, 8),
  AgeDecade = factor(c(5, 5, 4, 4, 3, 3)),  # Age in decades (3 = 30s, 4 = 40s, 5 = 50s)
  Female = c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE),
  Income = factor(c(3, 2, 1, 3, 2, 1)),  # Income levels (1 = low, 2 = medium, 3 = high)
  DisabilityGrade = factor(c("Mild", "Severe", "Mild", "Severe", "Mild", "Severe")),
  Anxiety = c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE)
)

example_test_data <- tibble(
  EndTime.is.Case.confirm.365 = c(1, 0, 1),
  EndTime = c(4, 12, 9),
  AgeDecade = factor(c(5, 3, 4)),
  Female = c(TRUE, FALSE, TRUE),
  Income = factor(c(3, 1, 2)),
  DisabilityGrade = factor(c("Severe", "Mild", "Severe")),
  Anxiety = c(FALSE, TRUE, FALSE)
)

# Ensure no randomness is used in creating the data
example_train_data
example_test_data

```
  
  
## :: TheTrainSet() ----  
### :: TheTestSet() ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

# Define variable names
varnames <- c(
  "EndTime.is.Case.confirm.365", "EndTime", "AgeDecade", "Female", "Income",
  "DisabilityGrade", "AcquiredHypothyroidism", "AdjustmentDisorder", "Anemia",
  "Anxiety", "Arthritis", "AtrialFibrillation", "BenignProstatic",
  "BrainInjury", "Cataract", "ChronicKidney", "Diabetes", "Dysthymia",
  "Epilepsy", "Fibromyalgia_Pain_Fatigue", "Glaucoma", "HearingImpairment",
  "HeartFailure", "Hyperlipidemia", "Hypertension", "IschemicHeart",
  "Migraine_ChronicHeadache", "MobilityImpairments", "Osteoporosis",
  "PelvicFx", "PersonalityDisorders", "SpinalCordInjury", "StrokeTIA",
  "AlzheimerDementia", "LiverDisease", "ObstructiveLungDisease",
  "CancerSurvivors"
)

# Create Training Dataset
TheTrainSet <- tibble(
  EndTime.is.Case.confirm.365 = c(0, 1, 0, 1, 0),
  EndTime = c(100, 200, 150, 300, 250),
  AgeDecade = c(5, 6, 5, 7, 6),
  Female = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  Income = c(3, 5, 2, 4, 3),
  DisabilityGrade = factor(c("None", "Severe", "Mild", "None", "Severe")),
  AcquiredHypothyroidism = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  AdjustmentDisorder = c(FALSE, FALSE, TRUE, FALSE, FALSE),
  Anemia = c(TRUE, FALSE, FALSE, TRUE, FALSE),
  Anxiety = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  Arthritis = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  AtrialFibrillation = c(FALSE, FALSE, TRUE, FALSE, FALSE),
  BenignProstatic = c(FALSE, FALSE, FALSE, FALSE, FALSE),
  BrainInjury = c(FALSE, TRUE, FALSE, FALSE, FALSE),
  Cataract = c(FALSE, FALSE, TRUE, FALSE, TRUE),
  ChronicKidney = c(FALSE, FALSE, FALSE, TRUE, FALSE),
  Diabetes = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  Dysthymia = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  Epilepsy = c(FALSE, FALSE, TRUE, FALSE, FALSE),
  Fibromyalgia_Pain_Fatigue = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  Glaucoma = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  HearingImpairment = c(FALSE, FALSE, FALSE, TRUE, FALSE),
  HeartFailure = c(FALSE, TRUE, FALSE, FALSE, FALSE),
  Hyperlipidemia = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  Hypertension = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  IschemicHeart = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  Migraine_ChronicHeadache = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  MobilityImpairments = c(FALSE, FALSE, TRUE, FALSE, FALSE),
  Osteoporosis = c(TRUE, FALSE, TRUE, FALSE, TRUE),
  PelvicFx = c(FALSE, TRUE, FALSE, TRUE, FALSE),
  PersonalityDisorders = c(FALSE, TRUE, FALSE, FALSE, FALSE),
  SpinalCordInjury = c(FALSE, FALSE, TRUE, FALSE, FALSE),
  StrokeTIA = c(FALSE, TRUE, FALSE, FALSE, FALSE),
  AlzheimerDementia = c(FALSE, FALSE, FALSE, TRUE, FALSE),
  LiverDisease = c(FALSE, TRUE, FALSE, FALSE, TRUE),
  ObstructiveLungDisease = c(FALSE, TRUE, FALSE, FALSE, TRUE),
  CancerSurvivors = c(FALSE, TRUE, FALSE, FALSE, FALSE)
)

# Create Test Dataset
TheTestSet <- tibble(
  EndTime.is.Case.confirm.365 = c(0, 1, 0),
  EndTime = c(120, 220, 180),
  AgeDecade = c(5, 7, 6),
  Female = c(FALSE, TRUE, FALSE),
  Income = c(4, 3, 5),
  DisabilityGrade = factor(c("Mild", "None", "Severe")),
  AcquiredHypothyroidism = c(TRUE, FALSE, TRUE),
  AdjustmentDisorder = c(FALSE, TRUE, FALSE),
  Anemia = c(FALSE, TRUE, FALSE),
  Anxiety = c(TRUE, FALSE, TRUE),
  Arthritis = c(FALSE, TRUE, FALSE),
  AtrialFibrillation = c(TRUE, FALSE, FALSE),
  BenignProstatic = c(FALSE, FALSE, FALSE),
  BrainInjury = c(TRUE, FALSE, FALSE),
  Cataract = c(FALSE, TRUE, FALSE),
  ChronicKidney = c(TRUE, FALSE, TRUE),
  Diabetes = c(FALSE, TRUE, FALSE),
  Dysthymia = c(TRUE, FALSE, TRUE),
  Epilepsy = c(FALSE, TRUE, FALSE),
  Fibromyalgia_Pain_Fatigue = c(FALSE, TRUE, FALSE),
  Glaucoma = c(TRUE, FALSE, TRUE),
  HearingImpairment = c(TRUE, FALSE, TRUE),
  HeartFailure = c(TRUE, FALSE, TRUE),
  Hyperlipidemia = c(FALSE, TRUE, FALSE),
  Hypertension = c(TRUE, FALSE, TRUE),
  IschemicHeart = c(FALSE, TRUE, FALSE),
  Migraine_ChronicHeadache = c(TRUE, FALSE, TRUE),
  MobilityImpairments = c(TRUE, FALSE, TRUE),
  Osteoporosis = c(FALSE, TRUE, FALSE),
  PelvicFx = c(TRUE, FALSE, TRUE),
  PersonalityDisorders = c(TRUE, FALSE, TRUE),
  SpinalCordInjury = c(TRUE, FALSE, TRUE),
  StrokeTIA = c(FALSE, TRUE, FALSE),
  AlzheimerDementia = c(TRUE, FALSE, TRUE),
  LiverDisease = c(TRUE, FALSE, TRUE),
  ObstructiveLungDisease = c(TRUE, FALSE, TRUE),
  CancerSurvivors = c(TRUE, FALSE, TRUE)
) %>%
  mutate(testset = TRUE)

TheTrainSet
TheTestSet
```
  
  
## glmnet::CoxExample ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# system.file("data", "CoxExample.rda", package = "glmnet")
# # > system.file("data", "CoxExample.rda", package = "glmnet")
# # [1] "/usr/local/lib/R/site-library/glmnet/data/CoxExample.rda"
# 
# library(glmnet)
# # load(system.file("data", "CoxExample.rda", package = "glmnet"))
# data(CoxExample)
# CoxExample |> str(max.level = 2, give.attr = TRUE)
# # CoxExample %>% map(function(mat) mat %>% round(3)) %>% deparse(width.cutoff = 500) %>% cat("\n")

load(url("https://raw.githubusercontent.com/mkim0710/tidystat/master/data/library_glmnet_glmnet_coxExample_tibble.rda"))
glmnet_coxExample_tibble
glmnet_coxExample_tibble.round3 = glmnet_coxExample_tibble %>% mutate(across(matches("V"), function(vec) round(vec, 3)))
glmnet_coxExample_tibble.round3
# glmnet_coxExample_tibble %>% write_csv(paste0(env1$path$path1,"/data/", "glmnet_coxExample_tibble", ".csv"))
# glmnet_coxExample_tibble.round3 %>% write_csv(paste0(env1$path$path1,"/data/", "glmnet_coxExample_tibble.round3", ".csv"))
```
  
  
    > glmnet_coxExample_tibble |> str(max.level = 2, give.attr = TRUE)
    tibble [1,000 Ã— 32] (S3: tbl_df/tbl/data.frame)
     $ time  : num [1:1000] 1.7688 0.5453 0.0449 0.8503 0.6149 ...
     $ status: num [1:1000] 1 1 0 0 1 0 0 1 1 0 ...
     $ V1    : num [1:1000] -0.877 -0.746 1.376 0.238 0.109 ...
     $ V2    : num [1:1000] -0.614 -1.752 -0.264 0.786 0.467 ...
     $ V3    : num [1:1000] -0.568 0.285 0.887 -0.897 -0.576 ...
     $ V4    : num [1:1000] 0.662 1.139 0.384 -0.834 1.704 ...
     $ V5    : num [1:1000] 1.8222 0.8018 0.0575 -0.5824 0.3275 ...
     $ V6    : num [1:1000] -1.091 1.85 -1.092 0.187 -0.121 ...
     $ V7    : num [1:1000] -0.332 0.307 0.821 -0.586 0.885 ...
     $ V8    : num [1:1000] 3.675 -1.373 2.296 0.476 0.451 ...
     $ V9    : num [1:1000] 0.2458 -0.0325 -0.4477 -0.6058 0.5888 ...
     $ V10   : num [1:1000] 1.138 0.748 -0.305 -1.27 0.55 ...
     $ V11   : num [1:1000] -0.46 -0.899 -3.682 0.868 0.552 ...
     $ V12   : num [1:1000] -0.618 0.282 1.313 -0.483 -1.105 ...
     $ V13   : num [1:1000] 0.365 1.542 -1.864 -0.101 1.598 ...
     $ V14   : num [1:1000] -1.365 0.222 -0.204 0.942 -0.339 ...
     $ V15   : num [1:1000] 1.79 -0.447 0.889 -0.235 -0.501 ...
     $ V16   : num [1:1000] -0.6 1.808 -0.396 0.262 -1.205 ...
     $ V17   : num [1:1000] 0.0712 1.541 0.5496 0.4586 -1.9601 ...
     $ V18   : num [1:1000] -1.107 1.762 0.163 0.389 -0.769 ...
     $ V19   : num [1:1000] 1.047 -0.911 -2.45 -1.539 0.714 ...
     $ V20   : num [1:1000] 0.0847 0.1854 -1.3069 -0.5914 1.2637 ...
     $ V21   : num [1:1000] 0.87 -0.443 0.393 -0.814 0.16 ...
     $ V22   : num [1:1000] -0.486 -0.136 1.112 -1.198 -1.063 ...
     $ V23   : num [1:1000] 0.23314 0.17755 0.00555 0.74975 1.7165 ...
     $ V24   : num [1:1000] -0.89 -0.121 -1.462 -0.983 -0.222 ...
     $ V25   : num [1:1000] 1.537 1.011 -1.3 2.005 0.785 ...
     $ V26   : num [1:1000] 0.362 0.978 -2.768 -0.571 -0.613 ...
     $ V27   : num [1:1000] -0.0518 0.9053 -0.1672 -0.2355 1.2637 ...
     $ V28   : num [1:1000] -0.178 -1.424 -0.7 0.939 -1.801 ...
     $ V29   : num [1:1000] 0.945 -0.733 0.929 0.363 -1.588 ...
     $ V30   : num [1:1000] 1.775 -0.0569 -1.5611 0.5486 1.0087 ...  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
# ã€šã€› SOURCE) Rdev/50_model_formula_evaluation/53_model_selection/f_df.cv.glmnet.source.r
# ã€šã€› RENDER) Rdev/50_model_formula_evaluation/53_model_selection/f_df.cv.glmnet.dev.Rmd
# ã€šã€› RENDER) Rdev/50_model_formula_evaluation/53_model_selection/f_cv_glmnet_object.plot.dev.Rmd
# ã€šã€› RENDER) Rdev/50_model_formula_evaluation/53_model_selection/f_df.cv.glmnet_alphas.dev.Rmd
# ã€šã€› RENDER) Rdev/50_model_formula_evaluation/53_model_selection/trainset.cv.glmnet_alphas_cox.dev.Rmd
# ã€šã€› RENDER) Rdev/60_communicate_report_export/f_df.glmnet.GT1.flextable.dev-GPT-pending.Rmd
# ã€šã€› RENDER) Rdev/60_communicate_report_export/f_df.glmnet.GT1.flextable.dev-Gemini-pending.Rmd

# __________|------  
# ã€šã€› START) dev ----  
# https://chatgpt.com/c/671605d9-92ac-800e-86da-6a01437532e9?model=gpt-4o
```{r env0-NoEchoNoResults, echo=FALSE, results="hide"}
env0 = env1
```
  
  
    trainset.cv.glmnet_alphas_cox <- function(
        trainset, 
        myFormula, 
        alphas = c(1, 0.5),
        glmnet.family = "cox", 
        my.type.measure = "deviance", 
        na.omit.needed = FALSE,
        return.glmnet.objects = TRUE, 
        saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha = FALSE,
        return_name = NULL, 
        itrainset = NULL, 
        imyFormula = NULL, 
        save.png = FALSE,
        png.size = 1280, 
        seed = 1, 
        nfolds = 5
    ) { 
        # ... (rest of the function) ...
    
        # Helper function to prepare data for glmnet
        prepare_data_for_glmnet <- function(trainset, myFormula) {
            # ... (code to create design matrices and handle missing data) ...
        }
    
        # Helper function to fit glmnet model
        fit_glmnet_model <- function(x, y, alpha, glmnet.family, my.type.measure, nfolds) {
            # ... (code to fit cv.glmnet) ...
        }
    
        # ... (rest of the function) ...
    
        # Prepare data
        x <- prepare_data_for_glmnet(trainset, myFormula)
    
        # Fit models for each alpha
        return_list <- lapply(seq_along(alphas), function(i_alpha) {
            # ... (use fit_glmnet_model() here) ...
        })
    
        # ... (rest of the function) ...
    }
  
  
  
## trainset.cv.glmnet_alphas_cox() ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
#' Perform Cross-Validated Cox Regression with glmnet
#'
#' This function performs cross-validated Cox regression using the glmnet package, 
#' allowing for different alpha values (elastic net mixing parameter). It provides
#' options for data preprocessing, model fitting, result saving, and plotting.
#'
#' @param trainset A data frame containing the training data.
#' @param myFormula A formula object specifying the model.
#' @param alphas A numeric vector of alpha values (mixing parameter for elastic net). 
#'   Default is c(1, 0.5) which corresponds to lasso and elastic net penalties.
#' @param glmnet.family A character string specifying the glmnet family. 
#'   Default is "cox".
#' @param my.type.measure A character string specifying the type of measure for 
#'   cross-validation. Default is "deviance", which represents the partial 
#'   likelihood deviance.  Other options include "C" for Harrell's concordance 
#'   index.
#' @param na.omit.needed Logical. Should missing values be removed? Default is FALSE.
#'   If TRUE, rows with any missing values in the predictors or outcome variables 
#'   will be removed.
#' @param return.glmnet.objects Logical. Should the cv.glmnet objects be returned? 
#'   Default is TRUE. If FALSE, only the file paths to the saved RDS files and plots
#'   will be returned.
#' @param saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha Logical. 
#'   Should the results be saved as RDS files? Default is FALSE. If TRUE, each 
#'   cv.glmnet object will be saved as an RDS file with a FileName based on the 
#'   `return_name`, `itrainset`, `imyFormula`, and the corresponding alpha value.
#' @param return_name Optional character string to specify the base name for 
#'   returned objects and saved files. If NULL (default), the function will attempt 
#'   to extract a name from the `trainset` argument.
#' @param itrainset Optional character string to further identify the training set.
#'   This string is used in constructing FileNames for saved objects and plots.
#' @param imyFormula Optional character string to identify the formula used.
#'   This string is used in constructing FileNames for saved objects and plots.
#' @param save.png Logical. Should cross-validation plots be saved as PNG files? 
#'   Default is FALSE. If TRUE, a plot for each cv.glmnet object will be saved 
#'   as a PNG file.
#' @param png.size Numeric. Width and height of PNG plots in pixels. Default is 1280.
#' @param seed Numeric. Random seed for reproducibility. Default is 1. This seed 
#'   is used for splitting the data into folds during cross-validation, ensuring 
#'   that the results are consistent across different runs.
#' @param nfolds Numeric. Number of folds for cross-validation. Default is 5.
#' @param lambda  Optional numeric vector of lambda values to use for fitting the 
#'   model. If NULL (default), the lambda sequence is generated automatically by 
#'   `glmnet`. Providing a specific lambda sequence can be useful for fine-tuning
#'   the model or comparing results with different lambda values.
#'
#' @return A list of cv.glmnet objects (if `return.glmnet.objects` is TRUE) or 
#'   a list of file paths to the saved RDS files and plots (if 
#'   `return.glmnet.objects` is FALSE). Each element in the list corresponds to a 
#'   different alpha value.
#'
#' @details 
#' This function streamlines the process of fitting regularized Cox proportional 
#' hazards models using the `glmnet` package. The elastic net penalty, controlled 
#' by the `alphas` parameter, allows for a combination of L1 (lasso) and L2 
#' (ridge) regularization, which can be helpful for variable selection and 
#' dealing with correlated predictors.
#' 
#' The function includes features for handling missing data, removing 
#' zero-variance predictors, and generating cross-validation plots. It also provides
#' options for saving the fitted models and plots to files, enhancing 
#' reproducibility and facilitating further analysis.
#'
#' @seealso 
#' \code{\link[glmnet]{cv.glmnet}}, \code{\link[glmnet]{glmnet}}, 
#' \code{\link[survival]{coxph}}, \code{\link[survival]{Surv}}
#'
#' @examples
#' library(survival)
#' 
#' # Load example data (lung cancer data)
#' data(lung)
#' 
#' # Fit models with different alpha values
#' model_results <- trainset.cv.glmnet_alphas_cox(
#'   trainset = lung, 
#'   myFormula = Surv(time, status) ~ ., 
#'   alphas = c(1, 0.5, 0), 
#'   save.png = TRUE,
#'   return_name = "lung_model"
#' )
#' 
#' # Access the model for alpha = 1
#' lasso_model <- model_results$alpha1
#' 
#' # Print the cross-validation results
#' print(lasso_model)
#' 
#' # Plot the cross-validation results
#' plot(lasso_model)
#' 
#' # Get the coefficients for the model with minimum cross-validation error
#' coef(lasso_model, s = "lambda.min") 
#'
#' @export
trainset.cv.glmnet_alphas_cox <- function(
    trainset, 
    myFormula, 
    alphas = c(1, 0.5),
    glmnet.family = "cox", 
    my.type.measure = "deviance", 
    na.omit.needed = FALSE,
    return.glmnet.objects = TRUE, 
    saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha = FALSE,
    return_name = NULL, 
    itrainset = NULL, 
    imyFormula = NULL, 
    save.png = FALSE,
    png.size = 1280, 
    seed = 1, 
    nfolds = 5,
    lambda = NULL  # Add lambda argument
) { 
  # Input validation
  if (!is.data.frame(trainset)) {
    stop("`trainset` must be a data frame.")
  }
  if (!inherits(myFormula, "formula")) {
    stop("`myFormula` must be a formula object.")
  }
  if (!is.numeric(alphas) || any(alphas < 0) || any(alphas > 1)) {
    stop("`alphas` must be a numeric vector with values between 0 and 1.")
  }
  if (!is.character(glmnet.family) || length(glmnet.family) != 1 || 
      !glmnet.family %in% c("cox", "binomial", "gaussian", "poisson", 
                           "multinomial", "mgaussian")) {
    stop("Invalid `glmnet.family` specified.")
  }
  if (!is.character(my.type.measure) || length(my.type.measure) != 1 || 
      !my.type.measure %in% c("deviance", "class", "auc", "mse", "mae")) {
    stop("Invalid `my.type.measure` specified.")
  }
  if (!is.logical(na.omit.needed) || length(na.omit.needed) != 1) {
    stop("`na.omit.needed` must be a logical value (TRUE or FALSE).")
  }
  if (!is.logical(return.glmnet.objects) || length(return.glmnet.objects) != 1) {
    stop("`return.glmnet.objects` must be a logical value (TRUE or FALSE).")
  }
  if (!is.logical(saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha) || 
      length(saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha) != 1) {
    stop("`saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha` must be a logical value (TRUE or FALSE).")
  }
  if (!is.null(return_name) && 
      (!is.character(return_name) || length(return_name) != 1)) {
    stop("`return_name` must be a character string or NULL.")
  }
  if (!is.null(itrainset) && 
      (!is.character(itrainset) || length(itrainset) != 1)) {
    stop("`itrainset` must be a character string or NULL.")
  }
  if (!is.null(imyFormula) && 
      (!is.character(imyFormula) || length(imyFormula) != 1)) {
    stop("`imyFormula` must be a character string or NULL.")
  }
  if (!is.logical(save.png) || length(save.png) != 1) {
    stop("`save.png` must be a logical value (TRUE or FALSE).")
  }
  if (!is.numeric(png.size) || length(png.size) != 1 || png.size <= 0) {
    stop("`png.size` must be a positive numeric value.")
  }
  if (!is.numeric(seed) || length(seed) != 1) {
    stop("`seed` must be a numeric value.")
  }
  if (!is.numeric(nfolds) || length(nfolds) != 1 || nfolds <= 1) {
    stop("`nfolds` must be a numeric value greater than 1.")
  }
  if (!is.null(lambda) && !is.numeric(lambda)) {
    stop("`lambda` must be a numeric vector or NULL.")
  }


  # Load required libraries
  library(glmnet)
  library(useful) 
  library(survival)
  library(tidyverse)

  # Set seed for reproducibility
  set.seed(seed)

  # Store original dimensions of the trainset
  trainset_dim <- dim(trainset)
  trainset_dimnames <- dimnames(trainset)

  # Get information about the variables in the trainset
  trainset_colnames_levels <- tibble(
    colNum_original = 1:ncol(trainset),
    colnames = colnames(trainset),
    colnames_levels = colnames(trainset),
    col_class = map_chr(trainset, class),
    col_Nlevels = map_int(trainset, ~ max(1, length(levels(.x))))
  ) %>%
    filter(col_Nlevels > 1) %>%  # Keep only factor or logical variables
    mutate(
      colnames_levels = paste0(
        colnames, 
        map_chr(trainset, function(x) {
          if (is.factor(x)) { 
            paste0(levels(x), collapse = "") 
          } else if (is.logical(x)) { 
            "TRUE" 
          } else { 
            "" 
          }
        })
      )
    )

  # Handle return_name
  if (is.null(return_name)) {
    return_name <- deparse(substitute(trainset))
  }

  # Create strings for FileName construction
  paste_itrainset <- ifelse(!is.null(itrainset), paste0("_", itrainset), "")
  paste_imyFormula <- ifelse(!is.null(imyFormula), paste0("_", imyFormula), "")

  # Check for conflicting arguments
  if (!return.glmnet.objects && !saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha) {
    stop(
      "At least one of `return.glmnet.objects` or ",
      "`saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha` must be TRUE."
    )
  }

  # Remove missing values if requested
  if (na.omit.needed) {
    nrow1 <- nrow(trainset)
    trainset <- na.omit(trainset)
    nrow2 <- nrow(trainset)
    message(
      "na.omit.needed == TRUE: removing ", nrow1 - nrow2, " rows - ",
      "from ", nrow1, " rows to ", nrow2, " rows"
    )
  }

  # Convert trainset to data frame (in case it's a tibble)
  trainset <- as.data.frame(trainset)

  # Create design matrix
  x <- model.matrix(myFormula, data = trainset, contrasts.arg = lapply(trainset[, sapply(trainset, is.factor)], contrasts, contrasts = FALSE))[,-1]
  build.x.colnames_levels <- colnames(x)

  # Update trainset_colnames_levels with design matrix information
  trainset_colnames_levels <- trainset_colnames_levels %>%
    mutate(
      build.x.colnames_levels = colnames_levels %in% build.x.colnames_levels,
      colnames_levels.colSums0 = colnames_levels %in% 
                                   colnames(x)[which(colSums(x) == 0)]
    )

  # Remove zero-variance predictors
  if (any(trainset_colnames_levels$colnames_levels.colSums0)) {
    cols_to_remove <- trainset_colnames_levels %>%
      filter(colnames_levels.colSums0) %>%
      pull(colnames)

    x <- x[, !colnames(x) %in% cols_to_remove]
    trainset <- trainset[, !colnames(trainset) %in% cols_to_remove]
    message(
      "Removing zero-variance predictors: ", paste(cols_to_remove, collapse = ", ")
    )
  }

  # Check for large design matrices
  if (nrow(x) * ncol(x) > 2^31) {
    stop("Error: model.matrix size should be less than 2^31")
  }

  # Extract response variable (time and event)
  mf <- model.frame(myFormula, data = trainset)
  y <- model.extract(mf, "response")
  if (!inherits(y, "Surv")) stop("Response must be a survival object")

  # Extract terms from the formula
  Terms <- terms(mf)
  trainset_colnames_levels <- trainset_colnames_levels %>%
    mutate(
      Terms.term.labels = colnames %in% attr(Terms, "term.labels")
    )

  # Helper function to extract variable names from the formula
  terms.inner <- function(x) {
    if (inherits(x, "formula")) {
      if (length(x) == 3) {
        c(terms.inner(x[[2]]), terms.inner(x[[3]]))
      } else {
        terms.inner(x[[2]])
      }
    } else if (is.call(x) && (x[[1]] != as.name("$") && x[[1]] != as.name("["))) {
      if (x[[1]] == '+' || x[[1]] == '*' || x[[1]] == '-') {
        if (length(x) == 3) {
          c(terms.inner(x[[2]]), terms.inner(x[[3]]))
        } else {
          terms.inner(x[[2]])
        }
      } else if (x[[1]] == as.name("Surv")) {
        unlist(lapply(x[-1], terms.inner))
      } else {
        terms.inner(x[[2]])
      }
    } else {
      deparse(x)
    }
  }

  # Extract variable names for response and predictors
  if (length(attr(Terms, 'variables')) > 2) { 
    varname4y <- terms.inner(myFormula[1:2])
    varname4x <- terms.inner(myFormula[c(1,3)])
    if (any(!is.na(match(varname4y, varname4x)))) {
      warning("A variable appears on both sides of the formula")
    }
  }

  # Update trainset_colnames_levels with extracted variable names
  trainset_colnames_levels <- trainset_colnames_levels %>%
    mutate(
      terms.inner = case_when(
        colnames %in% varname4x ~ "varname4x",
        colnames %in% varname4y ~ "varname4y",
        TRUE ~ NA_character_
      )
    )

  # Fit glmnet models for each alpha
  model_list <- lapply(seq_along(alphas), function(i_alpha) {
    message("Fitting model with alpha = ", alphas[i_alpha])

    # Construct FileName for saving
    return_name.i.tmp <- paste0(
      return_name, paste_itrainset, ".cv.glmnet", paste_imyFormula, "_a", 
      alphas[i_alpha]
    )

    # Fit cv.glmnet model
    model <- cv.glmnet(
      x, y, 
      alpha = alphas[i_alpha], 
      family = glmnet.family, 
      type.measure = my.type.measure, 
      nfolds = nfolds,
      lambda = lambda  # Use provided lambda sequence if available
    )

    # Save model as RDS file
    if (saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha) {
      saveRDS(model, paste0(return_name.i.tmp, ".rds"))
      message("Saved model to: ", paste0(return_name.i.tmp, ".rds"))
    }

    # Save cross-validation plot
    if (save.png) {
      png(
        paste0(return_name.i.tmp, "_plot.png"), 
        width = png.size, height = png.size, units = "px", bg = "transparent"
      )
      plot(model, main = paste0(return_name.i.tmp, "_plot"), cex.main = 0.5)
      dev.off()
      message("Saved plot to: ", paste0(return_name.i.tmp, "_plot.png"))
    }

    # Return model object or file paths
    if (return.glmnet.objects) {
      return(model)
    } else {
      return(list(
        saveRDS = paste0(return_name.i.tmp, ".rds"), 
        png = paste0(return_name.i.tmp, "_plot.png")
      ))
    }
  })

  # Name the list elements according to alpha values
  names(model_list) <- paste0("alpha", alphas)

  # Add function input and metadata as attributes
  attr(model_list, "function.input") <- list(
    Call = match.call(expand.dots = TRUE),
    CreatedDate = Sys.time(),
    functionUsed = trainset.cv.glmnet_alphas_cox,
    trainset_name = deparse(substitute(trainset)),
    trainset_dim = trainset_dim,
    trainset_dimnames = trainset_dimnames,
    trainset_colnames_levels = trainset_colnames_levels,
    alphas = alphas,
    glmnet.family = glmnet.family, 
    my.type.measure = my.type.measure,
    na.omit.needed = na.omit.needed,
    return.glmnet.objects = return.glmnet.objects,
    saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha = 
      saveRDS_return_name_itrainset.cv.glmnet_imyFormula_ialpha,
    return_name = return_name,
    itrainset = itrainset,
    imyFormula = imyFormula,
    save.png = save.png,
    png.size = png.size, 
    seed = seed, 
    nfolds = nfolds,
    lambda = lambda  # Include lambda in the attributes
  )

  return(model_list)
}
```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```
  
  
# __________|------  
# ã€šã€› SOURCE) ----  
```{r RUN-ALL-CHUNKS-ABOVE, echo=FALSE, results="hide", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
#| RUN ALL CHUNKS ABOVE: CTRL+ALT+SHIFT+P |#
```


```{r .RelativeSubPath_FileName.source.r-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
options(width=120)
options(DEVMODE = TRUE);  # isTRUE(getOption("DEVMODE"))
# .RelativeSubPath=r"(rstudio-prefs\templates)"|>str_replace_all("\\\\","/")  # Using Raw Strings in R 4.0.0 and Later: The raw string literal, denoted by r"(...)", will not process \ as an escape character.
if(env1$f$f_object.is_not_null.nor_na.nor_blank(env1$path$LastSourceEditorContext.path_FileNameExt)) {    .RelativeSubPath = env1$path$LastSourceEditorContext.path_FileNameExt |> dirname() |> env1$f$f_path.relative()  ;    ".RelativeSubPath" |> env1$f$f_ObjectName.get.dput.ECHO()    }
# if(.RelativeSubPath!="") .RelativeSubPath |> normalizePath(winslash="/",mustWork=TRUE) |> utils::browseURL() |> try()
# .FileName.source.r = "default.template" |> paste0(".source.r")
if(env1$f$f_object.is_not_null.nor_na.nor_blank(env1$path$LastSourceEditorContext.path_FileNameExt)) {    .SourceName_root = env1$path$LastSourceEditorContext.path_FileNameExt |> basename() |> str_replace("\\.(dev|source)\\.(r|Rmd)$"|>regex(ignore_case=TRUE), "") |> str_replace("\\.(r|Rmd)$"|>regex(ignore_case=TRUE),"")  ;    ".SourceName_root" |> env1$f$f_ObjectName.get.dput.ECHO()    }
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
env1$env.internal$showCodeText2open.FileName.source.r(.RelativeSubPath, .FileName.source.r)
# #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
# # \% source( file.path(env1$path$source_base,.RelativeSubPath_FileName.source.r) )  ----  
# env1$f$f_sourcePath.execute_if_not_sourced(.RelativeSubPath_FileName.source.r = list(.RelativeSubPath, .FileName.source.r) %>% {.[nzchar(.)]} %>% c(fsep = "/") %>% {do.call(file.path, .)})
```
  
  
# __________|------  
# ã€šã€› START) function ----  
## \% |> create_summary_table()  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)
# Install and load required libraries
if (!require("glmnet")) install.packages("glmnet")
if (!require("flextable")) install.packages("flextable")
library(glmnet)
library(flextable)

# Define the function
create_summary_table <- function(dataset, byVar, alpha = 1, create_flextable = FALSE) {
  # Prepare data
  x <- model.matrix(as.formula(paste("~ . -", byVar)), data = dataset)
  y <- dataset[[byVar]]
  
  # Print intermediate values for debugging
  print("x:")
  print(head(x)) # Print the first few rows of x
  print("y:")
  print(head(y)) # Print the first few values of y
  
  # Perform lasso/elastic net regression
  # Force lambda to be numeric to avoid potential issues
  lambda_seq <- as.numeric(seq(0.01, 1, by = 0.01))
  print("lambda sequence:")
  print(head(lambda_seq)) # Print the first few lambda values
  model <- glmnet(x, y, alpha = alpha, lambda = lambda_seq) 

  # Extract lambda.min from the model object
  lambda.min <- model$lambda.min
  print("lambda.min:")
  print(lambda.min) # Print the value of lambda.min

  # Extract coefficients and other statistics (example)
  coefficients <- coef(model, s = lambda.min)
  # ... extract other statistics as needed ...
  
  # Create a data frame for the table
  table_data <- data.frame(
    Variable = rownames(coefficients),
    Coefficient = coefficients[, 1]
    # ... add other statistics to the data frame ...
  )
  
  if (create_flextable) {
      # Create and format the flextable
      ft <- flextable(table_data)
      ft <- set_header_labels(ft, Variable = "Variable", Coefficient = "Coefficient")
      # ... add other formatting options as desired ...
      return(ft)
  } else {
      return(table_data)
  }
}



```
  
  
###### \% df_5vars_10obs |> create_summary_table() ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

# Use the provided dataset (same as before)
df_5vars_10obs <- data.frame(
  Group = rep(c("Group1", "Group2"), each = 5),
  Var1 = c(2.5, 3.0, 2.8, 2.9, 3.1, 3.6, 3.7, 3.5, 3.8, 3.9),
  Var2 = c(7.1, 7.3, 7.2, 7.4, 7.5, 6.8, 6.9, 7.0, 6.7, 6.6),
  Var3 = c(15, 16, 15, 14, 15, 18, 17, 19, 18, 17),
  Var4 = c(0.5, 0.6, 0.55, 0.58, 0.57, 0.65, 0.66, 0.64, 0.67, 0.68),
  Var5 = c(100, 105, 102, 101, 103, 110, 112, 111, 113, 114)
)

# Apply the create_summary_table function
lasso_table <- create_summary_table(dataset = df_5vars_10obs, byVar = "Var1", alpha = 1)

# Print the table
print(lasso_table)
```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)
library(reticulate)
system("python2 --version")
system("python3 --version")
```


```{py, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
import pandas as pd
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
import numpy as np

# Define the function
def create_summary_table(dataset, byVar, alpha=1):
    # Prepare data
    X = dataset.drop(byVar, axis=1)
    if 'Group' in X:
      X = pd.get_dummies(X, columns=['Group'], drop_first=True)
    y = dataset[byVar]

    # Perform lasso/elastic net regression
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Generate a lambda sequence
    lambdas = np.logspace(-4, 4, 100)

    model = Lasso(alpha=alpha)
    model.fit(X_scaled, y)

    # Extract coefficients and other statistics (example)
    coefficients = model.coef_
    intercept = model.intercept_

    # Create a data frame for the table
    table_data = pd.DataFrame({
        'Variable': X.columns,
        'Coefficient': coefficients
    })

    # Add intercept to table_data
    table_data.loc[len(table_data)] = ['Intercept', intercept]

    return table_data

# Use the provided dataset
df_5vars_10obs = pd.DataFrame({
    'Group': ['Group1'] * 5 + ['Group2'] * 5,
    'Var1': [2.5, 3.0, 2.8, 2.9, 3.1, 3.6, 3.7, 3.5, 3.8, 3.9],
    'Var2': [7.1, 7.3, 7.2, 7.4, 7.5, 6.8, 6.9, 7.0, 6.7, 6.6],
    'Var3': [15, 16, 15, 14, 15, 18, 17, 19, 18, 17],
    'Var4': [0.5, 0.6, 0.55, 0.58, 0.57, 0.65, 0.66, 0.64, 0.67, 0.68],
    'Var5': [100, 105, 102, 101, 103, 110, 112, 111, 113, 114]
})

# Apply the create_summary_table function
lasso_table = create_summary_table(dataset=df_5vars_10obs, byVar='Var1', alpha=1)

# Print the table
print(lasso_table.to_markdown(index=False, numalign="left", stralign="left"))
```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
###### \% |> () ----  
```{r, echo=FALSE, results="markup", collapse=TRUE, paged.print=FALSE, comment="", R.options=list(width=120)}
options(width=120)

```
  
  
  
# __________|------  
# ã€šã€› END ----  
```{r END-NoEvalNoEchoNoMsgNoResults, eval=FALSE, echo=FALSE, warning=TRUE, message=NA, results="hide", collapse=TRUE, paged.print=FALSE}
##________________________________________________________________________________  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
##++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++  
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
##________________________________________________________________________________  
##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  
# ã€šã€› END ----  
cat("    ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::    \n")
cat("    [][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][][]    \n")
cat("    {}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}    \n")
cat("    ()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()()    \n")
cat("    <><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>    \n")
cat("    HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH    \n")
cat("    OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO    \n")
cat("    XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX    \n")
cat("    VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV    \n")
cat("    WWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW    \n")
cat("    -|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|    \n")
cat("    ________________________________________________________________________    \n")
cat("    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n")
cat("    ************************************************************************    \n")
cat("    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n")
cat("    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n")
```
  
  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```

  
###### ECHO \% |> () ----  
```{r, echo=TRUE, results="markup", collapse=TRUE, paged.print=FALSE, comment="#", R.options=list(width=120)}
options(width=120)

```

  
  
```{r createBACKUP, eval=TRUE, include=FALSE}
if (Sys.getenv("PARENT_RENDERING") != "YES") {
    # if (Sys.info()["sysname"] == "Windows") {
        env1$env.internal.attach$f_FileNameExt.createBACKUP(BACKUP_from_path_FileNameExt = rstudioapi::getSourceEditorContext()$path|>str_replace("\\.([[:alnum:]]+)$",".Rmd"), .BACKUP_to_path="-BACKUP", timeFormat="%y%m%dT%H", overwrite=TRUE)
        # env1$env.internal.attach$f_FileNameExt.createBACKUP(BACKUP_from_path_FileNameExt = rstudioapi::getSourceEditorContext()$path|>str_replace("\\.([[:alnum:]]+)$",".nb.html"), .BACKUP_to_path="-BACKUP", timeFormat="%y%m%dT%H", overwrite=TRUE)
    # }
}
```
  
  
```{r Render-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
env1$path$LastSourceEditorContext.path_FileName.pdf = env1$path$LastSourceEditorContext.path_FileNameExt |> str_replace("\\.([[:alnum:]]+)$",".pdf") |> str_replace_all('[ <>()|\\:&;#?*\']', "-")
env1$path$LastSourceEditorContext.path_FileName.html = env1$path$LastSourceEditorContext.path_FileNameExt |> str_replace("\\.([[:alnum:]]+)$",".html") |> str_replace_all('[ <>()|\\:&;#?*\']', "-")
if (Sys.getenv("PARENT_RENDERING") != "YES") {
    if (Sys.info()["sysname"] == "Windows") {
        .tlmgr_installed_packages <- system2("tlmgr", args = c("info", "--list", "--only-installed"), stdout = TRUE)
        for (.font_name in c("roboto", "cascadia-code")) if(.tlmgr_installed_packages |> str_subset(.font_name) |> length() == 0) tinytex::tlmgr_install(.font_name)

        cat('Starting: rstudioapi::getSourceEditorContext()$path |> rmarkdown::render(output_dir = ',deparse(dirname(env1$path$LastSourceEditorContext.path_FileNameExt)),', output_format = "pdf_document")  \n')
        Sys.setenv(PARENT_RENDERING = "YES"); env1$path$LastSourceEditorContext.path_FileNameExt |> normalizePath(winslash="/",mustWork=NA) %>% {rmarkdown::render(input = .,output_dir = dirname(.), output_format = "pdf_document")}; Sys.setenv(PARENT_RENDERING = "NO")
        .path_file = env1$path$LastSourceEditorContext.path_FileName.pdf
        env1$f$f_file.git_lfs_track_add_f(.path_file = .path_file, EXECUTE = FALSE)
        env1$env.internal.attach$f_FileNameExt.createBACKUP(BACKUP_from_path_FileNameExt = .path_file, .BACKUP_to_path="-BACKUP", timeFormat="%y%m%dT%H", overwrite=TRUE)
        try(env1$env.internal.attach$f_file_PDF.sumatra(.path_file))
    }
}
# env1$path$LastSourceEditorContext.path_FileNameExt |> normalizePath(winslash="/",mustWork=NA) %>% {cat('  Sys.setenv(PARENT_RENDERING = "YES"); rmarkdown::render(input = ',deparse(.),', output_dir = ',deparse(dirname(.)),', output_format = "pdf_document"); Sys.setenv(PARENT_RENDERING = "NO")  \n', sep="")}; .path_file = env1$path$LastSourceEditorContext.path_FileName.pdf; env1$f$f_file.git_lfs_track_add_f(.path_file = .path_file, EXECUTE = FALSE); cat('  env1$env.internal.attach$f_FileNameExt.createBACKUP(BACKUP_from_path_FileNameExt = ',deparse(.path_file),', .BACKUP_to_path="-BACKUP", timeFormat="%y%m%dT%H", overwrite=TRUE)  \n', sep=""); if (Sys.info()["sysname"] == "Windows") { cat('  env1$env.internal.attach$f_file_PDF.sumatra(',deparse(.path_file),')  \n', sep="") } else { cat('  browseURL(',deparse(.path_file),')  \n', sep="") }
# cat("    ________________________________________________________________________    \n")
env1$path$LastSourceEditorContext.path_FileNameExt |> normalizePath(winslash="/",mustWork=NA) %>% {cat('  Sys.setenv(PARENT_RENDERING = "YES"); rmarkdown::render(input = ',deparse(.),', output_dir = ',deparse(dirname(.)),', output_format = "html_document"); Sys.setenv(PARENT_RENDERING = "NO")  \n', sep="")}; .path_file = env1$path$LastSourceEditorContext.path_FileName.html; env1$f$f_file.git_lfs_track_add_f(.path_file = .path_file, EXECUTE = FALSE); cat('  env1$env.internal.attach$f_FileNameExt.createBACKUP(BACKUP_from_path_FileNameExt = ',deparse(.path_file),', .BACKUP_to_path="-BACKUP", timeFormat="%y%m%dT%H", overwrite=TRUE)  \n', sep=""); cat('  env1$env.internal.attach$f_URL.browse_in_edge_app(',deparse(.path_file),')  \n', sep="")
```
  
  
```{r gitCheckout-NoEchoNoMsgNoResults, echo=FALSE, warning=TRUE, message=NA, results="hide"}
rstudioapi::getSourceEditorContext()$path %>% {env1$source[[basename(.)]] = .}
env1$path$LastSourceEditorContext.path_FileName.nb.html = env1$path$LastSourceEditorContext.path_FileNameExt |> str_replace("\\.([[:alnum:]]+)$",".nb.html")
if (Sys.info()["sysname"] == "Windows" && Sys.getenv("PARENT_RENDERING") != "YES") {  try(  paste0('ping -n 5 127.0.0.1 > nul & "C:/Program Files (x86)/Microsoft/Edge/Application/msedge_proxy.exe" --app="',env1$path$LastSourceEditorContext.path_FileName.nb.html|>normalizePath(winslash="/",mustWork=TRUE),'"') |> shell(wait=FALSE)  )  }  # else { browseURL(env1$path$LastSourceEditorContext.path_FileName.nb.html|>normalizePath(winslash="/",mustWork=TRUE)) }
env1$f$showCodeText2openSourceInGitHub()
```
  
  
